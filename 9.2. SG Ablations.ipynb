{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2e8de4-b906-4fee-9d0c-3229574c71b8",
   "metadata": {},
   "source": [
    "# Experiment 9.2: Sine Gordon Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e1781-9514-460c-bd4d-954756b60985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "\n",
    "from src.equations import sg_res as pde_res\n",
    "\n",
    "from src.utils import _get_adam, _get_pde_collocs, _get_ic_collocs, model_eval, count_params, _get_colloc_indices, grad_norm\n",
    "from src.wrappers import SGModel\n",
    "\n",
    "import numpy as np\n",
    "from jax import device_get\n",
    "\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "result_file = os.path.join(results_dir, \"ablations_sg.pkl\")\n",
    "\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "RESULTS = dict()\n",
    "        \n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa8bfd-1c9b-4e2d-a9fa-d4d830e47607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fdc3451-f9ca-485a-86a2-f9284319a7a5",
   "metadata": {},
   "source": [
    "## Data & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875b929-1b19-47ab-b132-d60c0538be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocation points and ICs\n",
    "collocs_pool = _get_pde_collocs(ranges = [(0,1), (0,1)], sample_size = 400)\n",
    "ic_collocs = _get_ic_collocs(x_range = (0, 1), sample_size = 2**6)\n",
    "ic_data = jnp.sin(jnp.pi*ic_collocs[:,1]).reshape(-1,1)\n",
    "\n",
    "# Reference solution\n",
    "ref = np.load('data/sg.npz')\n",
    "refsol = jnp.array(ref['usol'])\n",
    "\n",
    "N_t, N_x = ref['usol'].shape\n",
    "t, x = ref['t'].flatten(), ref['x'].flatten()\n",
    "T, X = jnp.meshgrid(t, x, indexing='ij')\n",
    "coords = jnp.hstack([T.flatten()[:, None], X.flatten()[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433d98b-0036-4eb7-aaea-ec877aa277fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training epochs\n",
    "num_epochs = 100_000\n",
    "\n",
    "# Scheduler configurations\n",
    "learning_rate = 1e-3\n",
    "decay_steps = 2000\n",
    "decay_rate = 0.9\n",
    "warmup_steps = 1000\n",
    "\n",
    "# Define causal training parameters\n",
    "causal_tol = 1.0\n",
    "num_chunks = 32\n",
    "M = jnp.triu(jnp.ones((num_chunks, num_chunks)), k=1).T\n",
    "\n",
    "# Define Grad Norm parameters\n",
    "grad_mixing = 0.9\n",
    "f_grad_norm = 1000\n",
    "\n",
    "# Define resampling parameters\n",
    "batch_size = 2**12\n",
    "f_resample = 2000\n",
    "rad_a = 1.0\n",
    "rad_c = 1.0\n",
    "\n",
    "# Define RBA parameters\n",
    "RBA_gamma = 0.999\n",
    "RBA_eta = 0.01\n",
    "\n",
    "# Define model parameters\n",
    "n_in = collocs_pool.shape[1]\n",
    "n_out = 1\n",
    "D = 5\n",
    "period_axes = None\n",
    "sine_D = 5\n",
    "alpha = 0.0\n",
    "beta = 0.0\n",
    "init_scheme = {'type': 'glorot', 'gain': None, 'norm_pow': 0, 'distribution': 'uniform', 'sample_size': 10000}\n",
    "n_hidden = 16\n",
    "num_blocks = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48920ed-bd73-4e2f-9a9c-796ce042f466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "032247fd-5767-4c27-9f5b-cf1cf1d8ecd5",
   "metadata": {},
   "source": [
    "## Ablation 1: Only RBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044589a-5805-46e4-97d2-f1c5878771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, l_E, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Get new RBA weights\n",
    "    abs_res = jnp.abs(residuals)\n",
    "    l_E_new = (RBA_gamma*l_E) + (RBA_eta*abs_res/jnp.max(abs_res)) # shape (batch_size, 1)\n",
    "\n",
    "    # Multiply by RBA weights\n",
    "    w_resids = l_E_new * residuals # shape (batch_size, 1)\n",
    "\n",
    "    loss = jnp.mean(w_resids**2)\n",
    "    \n",
    "    return loss, l_E_new\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, l_I, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Get new RBA weights\n",
    "    abs_res = jnp.abs(ic_res)\n",
    "    l_I_new = (RBA_gamma*l_I) + (RBA_eta*abs_res/jnp.max(abs_res))\n",
    "\n",
    "    # Multiply by RBA weights\n",
    "    w_resids = l_I_new * ic_res\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(w_resids**2)\n",
    "\n",
    "    return loss, l_I_new\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I, l_E, l_I):\n",
    "\n",
    "    # PDE loss\n",
    "    (loss_E, l_E_new), grads_E = nnx.value_and_grad(pde_loss, has_aux=True)(model, l_E, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    (loss_I, l_I_new), grads_I = nnx.value_and_grad(ic_loss, has_aux=True)(model, l_I, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I, l_E_new, l_I_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc861ef3-a758-4124-9d4e-7a3344deb15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 1\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 1\"][idx] = dict()\n",
    "    \n",
    "    # Initialize RBA weights - full pool\n",
    "    l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "    # Also get RBAs for ICs\n",
    "    l_I = jnp.ones((ic_collocs.shape[0], 1))\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    l_E = l_E_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = SGModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                   init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                   period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I, l_E, l_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I, l_E, l_I)\n",
    "\n",
    "    tack = time.time()\n",
    "        \n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 1\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 1\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b3718-2a50-4ece-9418-347bf52a86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634e480-e05c-4549-a7f8-b41a7f8f8d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce53a135-257e-4e55-95b7-af913a0f2f3e",
   "metadata": {},
   "source": [
    "## Ablation 2: No RBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb644c9-6a3b-452b-86e4-73b2956ff80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Reshape residuals for causal training\n",
    "    residuals = residuals.reshape(num_chunks, -1) # shape (num_chunks, points)\n",
    "\n",
    "    # Get average loss per chunk\n",
    "    loss = jnp.mean(residuals**2, axis=1)\n",
    "\n",
    "    # Get causal weights\n",
    "    weights = jax.lax.stop_gradient(jnp.exp(-causal_tol * (M @ loss)))\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(weights * loss)\n",
    "\n",
    "    return weighted_loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def get_RAD_indices(model, collocs_pool, old_indices):\n",
    "\n",
    "    # Get full residuals\n",
    "    resids = pde_res(model, collocs_pool)\n",
    "    \n",
    "    # Get absolute\n",
    "    wa_resids = jnp.abs(resids)\n",
    "\n",
    "    # Raise to power rad_a\n",
    "    ea = jnp.power(wa_resids, rad_a)\n",
    "    \n",
    "    # Divide by mean and add rad_c\n",
    "    px = (ea/jnp.mean(ea)) + rad_c\n",
    "    \n",
    "    # Normalize\n",
    "    px_norm = (px / jnp.sum(px))[:,0]\n",
    "\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=px_norm, seed=seed)\n",
    "\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f355429a-dd7b-4521-850d-2c766b493c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 2\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 2\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = SGModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                   init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                   period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "        \n",
    "        # Perform grad norm\n",
    "        if (epoch != 0) and (epoch % f_grad_norm == 0):\n",
    "    \n",
    "            λ_Ε, λ_I = grad_norm(grads_E, grads_I, λ_E, λ_I, grad_mixing)\n",
    "    \n",
    "        # Perform RAD\n",
    "        if (epoch != 0) and (epoch % f_resample == 0):\n",
    "\n",
    "            # Get new indices after resampling\n",
    "            sorted_indices = get_RAD_indices(model, collocs_pool, sorted_indices)\n",
    "            # Set new batch of collocs\n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 2\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 2\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcabdec-53d8-42d0-9401-be1fe41250f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 2\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65357b4-0568-43fd-bfce-d6debc6fdef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b66cfd46-39a7-4334-9596-2664319d454d",
   "metadata": {},
   "source": [
    "## Ablation 3: No RBA & No RAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e132379-1c70-49d0-88c6-dd3ef8dffa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Reshape residuals for causal training\n",
    "    residuals = residuals.reshape(num_chunks, -1) # shape (num_chunks, points)\n",
    "\n",
    "    # Get average loss per chunk\n",
    "    loss = jnp.mean(residuals**2, axis=1)\n",
    "\n",
    "    # Get causal weights\n",
    "    weights = jax.lax.stop_gradient(jnp.exp(-causal_tol * (M @ loss)))\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(weights * loss)\n",
    "\n",
    "    return weighted_loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d8e17-3a7a-4d9a-92bc-ca287658719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 3\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 3\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = SGModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                   init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                   period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "        \n",
    "        # Perform grad norm\n",
    "        if (epoch != 0) and (epoch % f_grad_norm == 0):\n",
    "    \n",
    "            λ_Ε, λ_I = grad_norm(grads_E, grads_I, λ_E, λ_I, grad_mixing)\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 3\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 3\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0fb81-9b48-4ab7-b0e8-724f6fd61313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 3\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83e09b-d491-46ed-b6f3-e255b8994341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03c814f9-0e76-4e4f-af40-4fb0f4dca780",
   "metadata": {},
   "source": [
    "## Ablation 4: No RBA & No Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263e81a-f640-413c-9713-a783eebdbcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # loss\n",
    "    loss = jnp.mean(residuals**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def get_RAD_indices(model, collocs_pool, old_indices):\n",
    "\n",
    "    # Get full residuals\n",
    "    resids = pde_res(model, collocs_pool)\n",
    "    \n",
    "    # Get absolute\n",
    "    wa_resids = jnp.abs(resids)\n",
    "\n",
    "    # Raise to power rad_a\n",
    "    ea = jnp.power(wa_resids, rad_a)\n",
    "    \n",
    "    # Divide by mean and add rad_c\n",
    "    px = (ea/jnp.mean(ea)) + rad_c\n",
    "    \n",
    "    # Normalize\n",
    "    px_norm = (px / jnp.sum(px))[:,0]\n",
    "\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=px_norm, seed=seed)\n",
    "\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9ef83-a61c-4125-a890-48f359438d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 4\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 4\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = SGModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                   init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                   period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "        \n",
    "        # Perform grad norm\n",
    "        if (epoch != 0) and (epoch % f_grad_norm == 0):\n",
    "    \n",
    "            λ_Ε, λ_I = grad_norm(grads_E, grads_I, λ_E, λ_I, grad_mixing)\n",
    "    \n",
    "        # Perform RAD\n",
    "        if (epoch != 0) and (epoch % f_resample == 0):\n",
    "\n",
    "            # Get new indices after resampling\n",
    "            sorted_indices = get_RAD_indices(model, collocs_pool, sorted_indices)\n",
    "            # Set new batch of collocs\n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 4\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 4\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f0e22-d89d-400a-80d5-97301a6671e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 4\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdd348-c25b-4bd3-98fd-367e119b07ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17f5839a-952c-4dba-a725-cca08f3bae9d",
   "metadata": {},
   "source": [
    "## Ablation 5: No RBA & No Grad Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013dd146-78ed-4cf8-bbff-22799994886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Reshape residuals for causal training\n",
    "    residuals = residuals.reshape(num_chunks, -1) # shape (num_chunks, points)\n",
    "\n",
    "    # Get average loss per chunk\n",
    "    loss = jnp.mean(residuals**2, axis=1)\n",
    "\n",
    "    # Get causal weights\n",
    "    weights = jax.lax.stop_gradient(jnp.exp(-causal_tol * (M @ loss)))\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(weights * loss)\n",
    "\n",
    "    return weighted_loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def get_RAD_indices(model, collocs_pool, old_indices):\n",
    "\n",
    "    # Get full residuals\n",
    "    resids = pde_res(model, collocs_pool)\n",
    "    \n",
    "    # Get absolute\n",
    "    wa_resids = jnp.abs(resids)\n",
    "\n",
    "    # Raise to power rad_a\n",
    "    ea = jnp.power(wa_resids, rad_a)\n",
    "    \n",
    "    # Divide by mean and add rad_c\n",
    "    px = (ea/jnp.mean(ea)) + rad_c\n",
    "    \n",
    "    # Normalize\n",
    "    px_norm = (px / jnp.sum(px))[:,0]\n",
    "\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=px_norm, seed=seed)\n",
    "\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5b3d9-521f-480f-945e-a000c79161d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 5\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 5\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = SGModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                   init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                   period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "    \n",
    "        # Perform RAD\n",
    "        if (epoch != 0) and (epoch % f_resample == 0):\n",
    "\n",
    "            # Get new indices after resampling\n",
    "            sorted_indices = get_RAD_indices(model, collocs_pool, sorted_indices)\n",
    "            # Set new batch of collocs\n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 5\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 5\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586f720-0d89-4971-8f5d-15ae63532954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 5\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de09500-da54-4b74-a416-663254d7d115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "893b6dc7-e508-4197-aaa7-00eda4ca2e80",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e201f-d1c8-4d55-8a1a-ad1b44b1a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(result_file, \"rb\") as f:\n",
    "    RESULTS = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(results_dir, \"benchmarks_sg.pkl\"), \"rb\") as f:\n",
    "    rbn = pickle.load(f)\n",
    "\n",
    "rbn = rbn[(alpha,beta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d677692-5451-4593-b386-4c9c628391c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(results, rbn):\n",
    "\n",
    "    l2_values = []\n",
    "    for run in rbn.keys():\n",
    "        l2_values.append(rbn[run]['l2'])\n",
    "\n",
    "    mean = np.mean(l2_values)\n",
    "    sem = np.std(l2_values, ddof=1) / np.sqrt(len(l2_values))\n",
    "\n",
    "    print(f\"Original:\\t L^2 = {mean:.3e}  Error = {sem:.3e}\")\n",
    "    \n",
    "    for ablation, runs in results.items():\n",
    "        l2_values = [v['l2'] for v in runs.values()]\n",
    "        mean = np.mean(l2_values)\n",
    "        sem = np.std(l2_values, ddof=1) / np.sqrt(len(l2_values))\n",
    "        print(f\"{ablation}:\\t L^2 = {mean:.3e}  Error = {sem:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d54410-6f20-41dc-bf45-d657b1abb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(RESULTS, rbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fc8d6-9742-44a2-8c99-450cdee06246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
