{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2e8de4-b906-4fee-9d0c-3229574c71b8",
   "metadata": {},
   "source": [
    "# Experiment 2: PDE Solving with Chebyshev Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4baaf-a3b3-47ad-a57b-4016ae9ec2c2",
   "metadata": {},
   "source": [
    "We perform a grid search over varying architectures, to get an understanding of the behavior for small, medium and large KANs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e1781-9514-460c-bd4d-954756b60985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "\n",
    "from src.equations import burgers_res, helmholtz_14_res\n",
    "\n",
    "from src.kan import KAN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "import os\n",
    "\n",
    "def get_collocs(pde_name, N):\n",
    "        \n",
    "    if pde_name == \"burgers\":\n",
    "\n",
    "        # PDE collocation points\n",
    "        t_pde = jnp.linspace(0, 1, N)\n",
    "        x_pde = jnp.linspace(-1, 1, N)\n",
    "        T_pde, X_pde = jnp.meshgrid(t_pde, x_pde, indexing='ij')\n",
    "        pde_collocs = jnp.stack([T_pde.flatten(), X_pde.flatten()], axis=1) # (N^2, 2)\n",
    "    \n",
    "        # Initial condition: - sin(πx)\n",
    "        t_ic = jnp.array([0.0])\n",
    "        T_ic, X_ic = jnp.meshgrid(t_ic, x_pde, indexing='ij')\n",
    "        ic_collocs = jnp.stack([T_ic.flatten(), X_ic.flatten()], axis=1) # (N, 2)\n",
    "        ic_data = -jnp.sin(jnp.pi*ic_collocs[:,1]).reshape(-1,1) # (N, 1)\n",
    "\n",
    "        # Boundary conditions: u(t,-1) = u(t,1) = 0\n",
    "        x_bc_1 = jnp.array([-1.0])\n",
    "        T_bc_1, X_bc_1 = jnp.meshgrid(t_pde, x_bc_1, indexing='ij')\n",
    "        bc_1 = jnp.stack([T_bc_1.flatten(), X_bc_1.flatten()], axis=1) # (N, 2)\n",
    "        bc_1_data = jnp.zeros(bc_1.shape[0]).reshape(-1,1) # (N, 1)\n",
    "\n",
    "        x_bc_2 = jnp.array([1.0])\n",
    "        T_bc_2, X_bc_2 = jnp.meshgrid(t_pde, x_bc_2, indexing='ij')\n",
    "        bc_2 = jnp.stack([T_bc_2.flatten(), X_bc_2.flatten()], axis=1) # (N, 2)\n",
    "        bc_2_data = jnp.zeros(bc_2.shape[0]).reshape(-1,1) # (N, 1)\n",
    "\n",
    "        bc_collocs = jnp.concatenate([ic_collocs, bc_1, bc_2], axis=0)\n",
    "        bc_data = jnp.concatenate([ic_data, bc_1_data, bc_2_data], axis=0)\n",
    "\n",
    "    elif pde_name == \"helmholtz_1-4\":\n",
    "        # PDE collocation points\n",
    "        x_pde = jnp.linspace(-1, 1, N)\n",
    "        y_pde = jnp.linspace(-1, 1, N)\n",
    "        X_pde, Y_pde = jnp.meshgrid(x_pde, y_pde, indexing='ij')\n",
    "        pde_collocs = jnp.stack([X_pde.flatten(), Y_pde.flatten()], axis=1) # (N^2, 2)\n",
    "    \n",
    "        # Boundary conditions: u(-1,y) = u(1,y) = u(x,-1) = u(x,1) = 0\n",
    "        x_bc_1 = jnp.array([-1.0])\n",
    "        X_bc_1, Y_bc_1 = jnp.meshgrid(x_bc_1, y_pde, indexing='ij')\n",
    "        bc_1 = jnp.stack([X_bc_1.flatten(), Y_bc_1.flatten()], axis=1) # (N, 2)\n",
    "        bc_1_data = jnp.zeros(bc_1.shape[0]).reshape(-1,1) # (N, 1)\n",
    "\n",
    "        x_bc_2 = jnp.array([1.0])\n",
    "        X_bc_2, Y_bc_2 = jnp.meshgrid(x_bc_2, y_pde, indexing='ij')\n",
    "        bc_2 = jnp.stack([X_bc_2.flatten(), Y_bc_2.flatten()], axis=1) # (N, 2)\n",
    "        bc_2_data = jnp.zeros(bc_2.shape[0]).reshape(-1,1) # (N, 1)\n",
    "\n",
    "        y_bc_3 = jnp.array([-1.0])\n",
    "        X_bc_3, Y_bc_3 = jnp.meshgrid(x_pde, y_bc_3, indexing='ij')\n",
    "        bc_3 = jnp.stack([X_bc_3.flatten(), Y_bc_3.flatten()], axis=1) # (N, 2)\n",
    "        bc_3_data = jnp.zeros(bc_3.shape[0]).reshape(-1,1) # (N, 1)\n",
    "\n",
    "        y_bc_4 = jnp.array([1.0])\n",
    "        X_bc_4, Y_bc_4 = jnp.meshgrid(x_pde, y_bc_4, indexing='ij')\n",
    "        bc_4 = jnp.stack([X_bc_4.flatten(), Y_bc_4.flatten()], axis=1) # (N, 2)\n",
    "        bc_4_data = jnp.zeros(bc_4.shape[0]).reshape(-1,1) # (N, 1)\n",
    "\n",
    "        bc_collocs = jnp.concatenate([bc_1, bc_2, bc_3, bc_4], axis=0)\n",
    "        bc_data = jnp.concatenate([bc_1_data, bc_2_data, bc_3_data, bc_4_data], axis=0)\n",
    "\n",
    "    return pde_collocs, bc_collocs, bc_data\n",
    "\n",
    "\n",
    "def get_ref(pde_name):\n",
    "\n",
    "    ref = np.load(f'data/{pde_name}.npz')\n",
    "    refsol = jnp.array(ref['usol'])\n",
    "\n",
    "    N_t, N_x = ref['usol'].shape\n",
    "\n",
    "    if pde_name != \"helmholtz_1-4\":\n",
    "    \n",
    "        t = ref['t'].flatten()\n",
    "        x = ref['x'].flatten()\n",
    "        T, X = jnp.meshgrid(t, x, indexing='ij')\n",
    "        coords = jnp.stack([T.flatten(), X.flatten()], axis=1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        x = ref['x'].flatten()\n",
    "        y = ref['y'].flatten()\n",
    "        X, Y = jnp.meshgrid(x, y, indexing='ij')\n",
    "        coords = jnp.stack([X.flatten(), Y.flatten()], axis=1)\n",
    "\n",
    "    return refsol, coords\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Define the experiment\n",
    "experiment_name = \"small_pde_D8\"\n",
    "results_file = os.path.join(results_dir, f\"{experiment_name}.csv\")\n",
    "\n",
    "# Define the file header\n",
    "header = \"PDE, width, depth, init_type, run, loss, l2\"\n",
    "\n",
    "# Check if the file exists and write the header if it doesn't\n",
    "if not os.path.exists(results_file):\n",
    "    with open(results_file, \"w\") as file:\n",
    "        file.write(header + \"\\n\")\n",
    "        \n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655960a1-288f-43be-9e39-d95c76fcbc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4c59f55-5b9b-4a4a-a968-1c00d06fcf5f",
   "metadata": {},
   "source": [
    "## Grid-Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212d91e-24c7-4d04-868c-1953092eb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the studied PDEs\n",
    "pde_dict = {\"burgers\": burgers_res, \"helmholtz_1-4\": helmholtz_14_res}\n",
    "\n",
    "D = 8\n",
    "period_axes = None\n",
    "rff_std = None\n",
    "\n",
    "# Define the two types of initialization\n",
    "base_init = {'type': 'default'}\n",
    "glorot_init = {'type': 'glorot', 'gain': None, 'norm_pow': 0, 'distribution': 'uniform', 'sample_size': 10000}\n",
    "\n",
    "# Number of sampled points\n",
    "N_points = 2**6\n",
    "\n",
    "# Number of training iterations\n",
    "num_epochs = 5000\n",
    "\n",
    "# Define simple optimizer\n",
    "opt_type = optax.adam(learning_rate=0.001)\n",
    "\n",
    "# Architecture settings\n",
    "widths = [2, 4, 8, 16, 32, 64]\n",
    "depths = [2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3043cd9-1477-479f-968b-afee21029ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a75d7b70-6bc6-4501-8e9d-4f53ea2d7321",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76428312-c319-4121-a322-56bed8a15094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure\n",
    "for pde_name in pde_dict.keys():\n",
    "    print(f\"Running Experiments for {pde_name} PDE.\")\n",
    "    pde_res = pde_dict[pde_name]\n",
    "\n",
    "    # Define the loss function for this PDE\n",
    "    def loss_fn(model, pde_collocs, bc_collocs, bc_data):\n",
    "\n",
    "        # ------------- PDE ---------------------------- #\n",
    "        pde_residuals = pde_res(model, pde_collocs)\n",
    "    \n",
    "        pde_loss = jnp.mean(pde_residuals**2)\n",
    "    \n",
    "    \n",
    "        # ------------- BC ----------------------------- #\n",
    "        bc_residuals = model(bc_collocs) - bc_data\n",
    "    \n",
    "        bc_loss = jnp.mean(bc_residuals**2)\n",
    "    \n",
    "        \n",
    "        # ------------- Total --------------------------- #\n",
    "        total_loss = pde_loss + bc_loss\n",
    "    \n",
    "        return total_loss\n",
    "\n",
    "    # Define the train step\n",
    "    @nnx.jit\n",
    "    def train_step(model, optimizer, pde_collocs, bc_collocs, bc_data):\n",
    "        loss, grads = nnx.value_and_grad(loss_fn, has_aux = False)(model, pde_collocs, bc_collocs, bc_data)\n",
    "    \n",
    "        optimizer.update(grads)\n",
    "    \n",
    "        return loss\n",
    "\n",
    "    # Get the reference solution\n",
    "    refsol, coords = get_ref(pde_name)\n",
    "\n",
    "    # Get collocation points\n",
    "    pde_collocs, bc_collocs, bc_data = get_collocs(pde_name, N_points)\n",
    "\n",
    "    # Model input/output\n",
    "    n_in, n_out = pde_collocs.shape[1], bc_data.shape[1]\n",
    "\n",
    "    # Grid search over depth size\n",
    "    for depth in depths:\n",
    "\n",
    "        # Grid search over width size\n",
    "        for width in widths:\n",
    "\n",
    "            # Discern between baseline initialization and Glorot-like initialization\n",
    "            for init_scheme in [base_init, glorot_init]:\n",
    "\n",
    "                type_init = init_scheme['type']\n",
    "            \n",
    "                print(f\"\\tTraining model with depth = {depth} and width = {width} ({type_init} init).\")\n",
    "\n",
    "                for run in [1, 2, 3, 4, 5]:\n",
    "\n",
    "                    model = KAN(n_in = n_in, n_out = n_out, n_hidden = width, num_layers = depth, D = D,\n",
    "                                init_scheme = init_scheme, period_axes = period_axes, rff_std = rff_std,\n",
    "                                seed = seed+run)\n",
    "                    \n",
    "                    optimizer = nnx.Optimizer(model, opt_type)\n",
    "                \n",
    "                    # Train\n",
    "                    for epoch in range(num_epochs):\n",
    "                        train_loss = train_step(model, optimizer, pde_collocs, bc_collocs, bc_data)\n",
    "                \n",
    "                    # Evaluate\n",
    "                    output = model(coords).reshape(refsol.shape)\n",
    "                    l2error = jnp.linalg.norm(output-refsol)/jnp.linalg.norm(refsol)\n",
    "                \n",
    "                    # Log results\n",
    "                    new_row = f\"{pde_name}, {width}, {depth}, {type_init}, {run}, {train_loss}, {l2error}\"\n",
    "                                    \n",
    "                    # Append the row to the file\n",
    "                    with open(results_file, \"a\") as rfile:\n",
    "                        rfile.write(new_row + \"\\n\")\n",
    "\n",
    "                    print(f\"\\t\\t\\t{run}. Final loss: {train_loss:.2e} \\tRel. L2 Error: {l2error:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f72392-135d-4e66-865e-25fc66e0557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eec3c994-2a42-494c-929c-577ee9f3f986",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's first determine how many times glorot overshadows default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1a567-fc95-4cda-a8e8-6a7ecd6a5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "agg_func = \"mean\"   # or \"mean\"\n",
    "\n",
    "# -----------------------------\n",
    "# Font sizes\n",
    "# -----------------------------\n",
    "FONT = {\n",
    "    \"title\": 20,\n",
    "    \"xlabel\": 18,\n",
    "    \"ylabel\": 18,\n",
    "    \"ticks\": 16,\n",
    "    \"cbar_label\": 18,\n",
    "    \"cbar_ticks\": 16,\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Load & reduce data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(results_file, sep=', ')\n",
    "\n",
    "df = df[df[\"depth\"] != 1]                      # exclude depth=1\n",
    "\n",
    "df_red = (\n",
    "    df.groupby([\"PDE\", \"width\", \"depth\", \"init_type\"])[\"l2\"]\n",
    "      .agg(agg_func)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_pivot = df_red.pivot(index=[\"PDE\",\"width\",\"depth\"],\n",
    "                        columns=\"init_type\", values=\"l2\").reset_index()\n",
    "\n",
    "df_pivot[\"width\"] = pd.to_numeric(df_pivot[\"width\"])\n",
    "df_pivot[\"depth\"] = pd.to_numeric(df_pivot[\"depth\"])\n",
    "W = sorted(df_pivot[\"width\"].unique().tolist())\n",
    "D = sorted(df_pivot[\"depth\"].unique().tolist())\n",
    "\n",
    "pdes = sorted(df_pivot[\"PDE\"].unique().tolist())\n",
    "W = sorted(df_pivot[\"width\"].unique().tolist())\n",
    "D = sorted(df_pivot[\"depth\"].unique().tolist())\n",
    "\n",
    "def build_matrix_for_col(f, col):\n",
    "    sub = df_pivot[df_pivot[\"PDE\"] == f]\n",
    "    M = np.full((len(D), len(W)), np.nan)\n",
    "    for i, d in enumerate(D):\n",
    "        for j, w in enumerate(W):\n",
    "            row = sub[(sub[\"width\"] == w) & (sub[\"depth\"] == d)]\n",
    "            if not row.empty and col in row:\n",
    "                M[i, j] = row.iloc[0][col]\n",
    "    return M\n",
    "\n",
    "mats_glorot  = {f: build_matrix_for_col(f, \"glorot\")  for f in pdes}\n",
    "mats_default = {f: build_matrix_for_col(f, \"default\") for f in pdes}\n",
    "\n",
    "# helper: LaTeX title\n",
    "def pde_title(name: str) -> str:\n",
    "    if name == 'burgers':\n",
    "        return \"Burgers\"\n",
    "    else:\n",
    "        return \"Helmholtz\"\n",
    "\n",
    "mats_pct = {}\n",
    "mats_default_wins = {}\n",
    "for f in pdes:\n",
    "    G = mats_glorot[f]\n",
    "    Df = mats_default[f]\n",
    "    Mpct = np.full_like(G, np.nan, dtype=float)\n",
    "    Mwins = np.full_like(G, False, dtype=bool)\n",
    "    for i in range(len(D)):\n",
    "        for j in range(len(W)):\n",
    "            g, dft = G[i, j], Df[i, j]\n",
    "            if np.isfinite(g) and np.isfinite(dft) and dft > 0:\n",
    "                val = (dft - g) / dft * 100.0\n",
    "                if val >= 0:\n",
    "                    Mpct[i, j] = val        # keep Glorot improvements\n",
    "                Mwins[i, j] = (g > dft)    # True if Default wins\n",
    "    mats_pct[f] = Mpct\n",
    "    mats_default_wins[f] = Mwins\n",
    "\n",
    "# colormap\n",
    "cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "\n",
    "\n",
    "# -------- Figure: centered 3-over-2 mosaic --------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n",
    "\n",
    "im_last = None\n",
    "for ax, f in zip(axes, pdes):\n",
    "    Mpct = mats_pct[f]\n",
    "    wins_default = mats_default_wins[f]\n",
    "\n",
    "    # main heatmap (Glorot improvements, clipped 0–100 %)\n",
    "    im_last = ax.imshow(\n",
    "        Mpct,\n",
    "        cmap=cmap,\n",
    "        vmin=0, vmax=100,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "\n",
    "    # overlay solid red where Default wins\n",
    "    red_mask = np.where(wins_default, 1.0, np.nan)\n",
    "    ax.imshow(\n",
    "        red_mask,\n",
    "        cmap=colors.ListedColormap([\"black\"]),\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        alpha=0.85,\n",
    "        vmin=0.0, vmax=1.0,\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(range(len(W)))\n",
    "    ax.set_xticklabels(W, fontsize=FONT[\"ticks\"])\n",
    "    ax.set_yticks(range(len(D)))\n",
    "    ax.set_yticklabels(D, fontsize=FONT[\"ticks\"])\n",
    "    ax.set_xlabel(\"Hidden Layer Dimension\", fontsize=FONT[\"xlabel\"])\n",
    "    ax.set_ylabel(\"Hidden Layers\", fontsize=FONT[\"ylabel\"])\n",
    "    ax.set_title(pde_title(f), fontsize=FONT[\"title\"])\n",
    "\n",
    "# single shared colorbar at the right\n",
    "cbar = fig.colorbar(im_last, ax=axes, shrink=0.85, location=\"right\", pad=0.02)\n",
    "cbar.set_label(\"Initialization improvement\\nover Default (%)\", fontsize=FONT[\"cbar_label\"])\n",
    "cbar.ax.tick_params(labelsize=FONT[\"cbar_ticks\"])\n",
    "\n",
    "plt.savefig(f\"{plots_dir}/pdes_heat.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca41da-5886-4bff-9a1d-cc04224ed7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2415da62-4978-4962-8302-1c8ddd653717",
   "metadata": {},
   "source": [
    "## Loss Plots\n",
    "\n",
    "Given these results, we rerun some experiments to also derive plots for the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be2da3-7342-4fe1-8602-1d53dbd225a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict = dict()\n",
    "\n",
    "# Procedure\n",
    "for pde_name in pde_dict.keys():\n",
    "    print(f\"Running Experiments for {pde_name} PDE.\")\n",
    "    pde_res = pde_dict[pde_name]\n",
    "\n",
    "    loss_dict[pde_name] = dict()\n",
    "\n",
    "    # Define the loss function for this PDE\n",
    "    def loss_fn(model, pde_collocs, bc_collocs, bc_data):\n",
    "\n",
    "        # ------------- PDE ---------------------------- #\n",
    "        pde_residuals = pde_res(model, pde_collocs)\n",
    "    \n",
    "        pde_loss = jnp.mean(pde_residuals**2)\n",
    "    \n",
    "    \n",
    "        # ------------- BC ----------------------------- #\n",
    "        bc_residuals = model(bc_collocs) - bc_data\n",
    "    \n",
    "        bc_loss = jnp.mean(bc_residuals**2)\n",
    "    \n",
    "        \n",
    "        # ------------- Total --------------------------- #\n",
    "        total_loss = pde_loss + bc_loss\n",
    "    \n",
    "        return total_loss\n",
    "\n",
    "    # Define the train step\n",
    "    @nnx.jit\n",
    "    def train_step(model, optimizer, pde_collocs, bc_collocs, bc_data):\n",
    "        loss, grads = nnx.value_and_grad(loss_fn, has_aux = False)(model, pde_collocs, bc_collocs, bc_data)\n",
    "    \n",
    "        optimizer.update(grads)\n",
    "    \n",
    "        return loss\n",
    "\n",
    "    # Get the reference solution\n",
    "    refsol, coords = get_ref(pde_name)\n",
    "\n",
    "    # Get collocation points\n",
    "    pde_collocs, bc_collocs, bc_data = get_collocs(pde_name, N_points)\n",
    "\n",
    "    # Model input/output\n",
    "    n_in, n_out = pde_collocs.shape[1], bc_data.shape[1]\n",
    "\n",
    "    # Different architectures\n",
    "    for arch_name, arch in zip([\"small\", \"big\"], [(4, 3), (16, 5)]):\n",
    "\n",
    "        loss_dict[pde_name][arch_name] = dict()\n",
    "\n",
    "        width, depth = arch\n",
    "\n",
    "        # Discern between baseline initialization and Glorot-like initialization\n",
    "        for init_scheme in [base_init, glorot_init]:\n",
    "\n",
    "            type_init = init_scheme['type']\n",
    "\n",
    "            loss_dict[pde_name][arch_name][type_init] = []\n",
    "            train_losses = jnp.zeros(num_epochs)\n",
    "        \n",
    "            print(f\"\\tTraining model with depth = {depth} and width = {width} ({type_init} init).\")\n",
    "\n",
    "            for run in [1, 2, 3, 4, 5]:\n",
    "\n",
    "                model = KAN(n_in = n_in, n_out = n_out, n_hidden = width, num_layers = depth, D = D,\n",
    "                            init_scheme = init_scheme, period_axes = period_axes, rff_std = rff_std,\n",
    "                            seed = seed+run)\n",
    "                \n",
    "                optimizer = nnx.Optimizer(model, opt_type)\n",
    "            \n",
    "                # Train\n",
    "                for epoch in range(num_epochs):\n",
    "                    train_loss = train_step(model, optimizer, pde_collocs, bc_collocs, bc_data)\n",
    "                    train_losses = train_losses.at[epoch].set(train_loss)\n",
    "            \n",
    "                # Evaluate\n",
    "                output = model(coords).reshape(refsol.shape)\n",
    "                l2error = jnp.linalg.norm(output-refsol)/jnp.linalg.norm(refsol)\n",
    "            \n",
    "                loss_dict[pde_name][arch_name][type_init].append(train_losses)\n",
    "\n",
    "                print(f\"\\t\\t{run}. Final loss: {train_loss:.2e} \\tRel. L2 Error: {l2error:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d55fb9-9db7-4be0-b289-fb65fa90da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "loss_file = os.path.join(results_dir, \"pde_losses.pkl\")\n",
    "\n",
    "with open(loss_file, \"wb\") as f:\n",
    "    pickle.dump(loss_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7217f-5fb0-4b11-bc71-500e5deffada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(results_dir, \"pde_losses.pkl\"), \"rb\") as f:\n",
    "    loss_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb12fa1-65ed-4cd3-a942-066cc68cbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (\n",
    "    LogLocator, LogFormatterMathtext,\n",
    "    FixedLocator, NullLocator, NullFormatter\n",
    ")\n",
    "\n",
    "# --- config you can tweak ---\n",
    "PDES = pdes\n",
    "ARCHS = [\"small\", \"big\"]\n",
    "TITLE_FS = 22\n",
    "LABEL_FS = 20\n",
    "TICK_FS  = 18\n",
    "LEGEND_FS = 20\n",
    "\n",
    "cmap = plt.get_cmap(\"Spectral_r\")\n",
    "cmap_points = np.linspace(0, 1, 12)\n",
    "color_indices = [-2, 1]\n",
    "colors = [cmap(cmap_points[i]) for i in color_indices]\n",
    "\n",
    "def _stack_runs(runs):\n",
    "    \"\"\"Stack a list of 1D arrays to shape (n_runs, n_epochs), trimming to min length if needed.\"\"\"\n",
    "    runs = [np.asarray(r).ravel() for r in runs if r is not None]\n",
    "    if not runs:\n",
    "        return None\n",
    "    m = min(map(len, runs))\n",
    "    return np.stack([r[:m] for r in runs], axis=0).astype(float)\n",
    "\n",
    "def _set_log_ticks(ax, tick_fs, fixed_ticks=None):\n",
    "    ax.set_yscale(\"log\")\n",
    "    if fixed_ticks is None:\n",
    "        # powers-of-10 only, no minor ticks\n",
    "        ax.yaxis.set_major_locator(LogLocator(base=10.0))\n",
    "        ax.yaxis.set_major_formatter(LogFormatterMathtext(base=10.0))\n",
    "        ax.yaxis.set_minor_locator(NullLocator())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "    else:\n",
    "        # exact ticks you want (e.g., [1e4]) and nothing else\n",
    "        ax.yaxis.set_major_locator(FixedLocator(fixed_ticks))\n",
    "        #ax.yaxis.set_major_formatter(LogFormatterMathtext(base=10.0))\n",
    "        ax.yaxis.set_minor_locator(NullLocator())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "    ax.tick_params(axis=\"y\", which=\"both\", labelsize=tick_fs)\n",
    "\n",
    "def _plot_mean_with_se(ax, runs, label, color):\n",
    "    \"\"\"Plot mean ± standard error (shaded), return the line handle (for legend).\"\"\"\n",
    "    arr = _stack_runs(runs)\n",
    "    if arr is None:\n",
    "        return None\n",
    "    n = arr.shape[0]\n",
    "    x = np.arange(arr.shape[1])\n",
    "    mean = arr.mean(axis=0)\n",
    "    # ddof=1 for sample std; guard n=1\n",
    "    se = (arr.std(axis=0, ddof=1) / np.sqrt(n)) if n > 1 else np.zeros_like(mean)\n",
    "\n",
    "    line, = ax.plot(x, mean, label=label, linewidth=2.0, color=color)\n",
    "    ax.fill_between(x, mean - se, mean + se, alpha=0.25, color=color, linewidth=0)\n",
    "    return line\n",
    "\n",
    "def plot_training_curves(loss_dict):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 6), sharex=True, sharey=False, constrained_layout=True)\n",
    "\n",
    "    legend_handles = []\n",
    "\n",
    "    for col, func in enumerate(pdes):\n",
    "        for row, arch in enumerate(ARCHS):\n",
    "            ax = axes[row, col]\n",
    "            if row == 0 and col == 4:\n",
    "                _set_log_ticks(ax, TICK_FS, fixed_ticks=None)#[1.5e4])\n",
    "            elif row == 1 and col == 4:\n",
    "                _set_log_ticks(ax, TICK_FS, fixed_ticks=None)#[1e4])\n",
    "            else:\n",
    "                _set_log_ticks(ax, TICK_FS)\n",
    "                \n",
    "\n",
    "            # Pull runs safely; skip if missing\n",
    "            runs_default = loss_dict.get(func, {}).get(arch, {}).get(\"default\", [])\n",
    "            runs_glorot  = loss_dict.get(func, {}).get(arch, {}).get(\"glorot\",  [])\n",
    "\n",
    "            h1 = _plot_mean_with_se(ax, runs_default, \"Default Initialization\", color=colors[0])\n",
    "            h2 = _plot_mean_with_se(ax, runs_glorot,  \"Proposed Initialization\", color=colors[1])\n",
    "\n",
    "            # Titles only on top row\n",
    "            if row == 0:\n",
    "                ax.set_title(pde_title(func), fontsize=TITLE_FS)\n",
    "\n",
    "            # Axis labels on left and bottom edges\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(\"Training Loss\", fontsize=LABEL_FS)\n",
    "            if row == len(ARCHS) - 1:\n",
    "                ax.set_xlabel(\"Training Iteration\", fontsize=LABEL_FS)\n",
    "\n",
    "            ax.tick_params(labelsize=TICK_FS)\n",
    "\n",
    "            ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "            # Collect legend handles once (first subplot that has both)\n",
    "            if not legend_handles and (h1 is not None or h2 is not None):\n",
    "                legend_handles = [h for h in (h1, h2) if h is not None]\n",
    "\n",
    "    # annotate rows\n",
    "    axes[0, -1].annotate(\" 3 hidden layers\\n(dimension = 4)\",\n",
    "                         xy=(1.05, 0.5), xycoords=\"axes fraction\",\n",
    "                         ha=\"left\", va=\"center\", rotation=90, fontsize=LABEL_FS)\n",
    "    \n",
    "    axes[1, -1].annotate(\"  5 hidden layers\\n(dimension = 16)\",\n",
    "                         xy=(1.05, 0.5), xycoords=\"axes fraction\",\n",
    "                         ha=\"left\", va=\"center\", rotation=90, fontsize=LABEL_FS)\n",
    "\n",
    "    if legend_handles:\n",
    "        fig.legend(legend_handles, [h.get_label() for h in legend_handles],\n",
    "               loc=\"lower center\", ncol=2, frameon=False, fontsize=LEGEND_FS,\n",
    "               bbox_to_anchor=(0.5, -0.1))\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "# ---- call it ----\n",
    "fig, axes = plot_training_curves(loss_dict)\n",
    "plt.savefig(f\"{plots_dir}/pde_loss.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5cac34-b47d-41f1-893d-dc3ac9f0e4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70077ca9-ede1-4920-92bd-a30fe3f9a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import (\n",
    "    LogLocator, LogFormatterMathtext,\n",
    "    FixedLocator, NullLocator, NullFormatter\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "agg_func = \"mean\"   # or \"mean\"\n",
    "\n",
    "# -----------------------------\n",
    "# Font sizes\n",
    "# -----------------------------\n",
    "FONT = {\n",
    "    \"title\": 20,\n",
    "    \"xlabel\": 18,\n",
    "    \"ylabel\": 18,\n",
    "    \"ticks\": 16,\n",
    "    \"cbar_label\": 18,\n",
    "    \"cbar_ticks\": 16,\n",
    "}\n",
    "\n",
    "TITLE_FS = 22\n",
    "LABEL_FS = 20\n",
    "TICK_FS  = 18\n",
    "LEGEND_FS = 20\n",
    "\n",
    "ARCHS = [\"small\", \"big\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Load & reduce data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(results_file, sep=', ')\n",
    "\n",
    "df = df[df[\"depth\"] != 1]                      # exclude depth=1\n",
    "\n",
    "df_red = (\n",
    "    df.groupby([\"PDE\", \"width\", \"depth\", \"init_type\"])[\"l2\"]\n",
    "      .agg(agg_func)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_pivot = df_red.pivot(index=[\"PDE\",\"width\",\"depth\"],\n",
    "                        columns=\"init_type\", values=\"l2\").reset_index()\n",
    "\n",
    "df_pivot[\"width\"] = pd.to_numeric(df_pivot[\"width\"])\n",
    "df_pivot[\"depth\"] = pd.to_numeric(df_pivot[\"depth\"])\n",
    "W = sorted(df_pivot[\"width\"].unique().tolist())\n",
    "D = sorted(df_pivot[\"depth\"].unique().tolist())\n",
    "\n",
    "pdes = sorted(df_pivot[\"PDE\"].unique().tolist())\n",
    "\n",
    "def build_matrix_for_col(f, col):\n",
    "    sub = df_pivot[df_pivot[\"PDE\"] == f]\n",
    "    M = np.full((len(D), len(W)), np.nan)\n",
    "    for i, d in enumerate(D):\n",
    "        for j, w in enumerate(W):\n",
    "            row = sub[(sub[\"width\"] == w) & (sub[\"depth\"] == d)]\n",
    "            if not row.empty and col in row:\n",
    "                M[i, j] = row.iloc[0][col]\n",
    "    return M\n",
    "\n",
    "mats_glorot  = {f: build_matrix_for_col(f, \"glorot\")  for f in pdes}\n",
    "mats_default = {f: build_matrix_for_col(f, \"default\") for f in pdes}\n",
    "\n",
    "# helper: LaTeX title\n",
    "def pde_title(name: str) -> str:\n",
    "    if name == 'burgers':\n",
    "        return \"Burgers\"\n",
    "    else:\n",
    "        return \"Helmholtz\"\n",
    "\n",
    "mats_pct = {}\n",
    "mats_default_wins = {}\n",
    "for f in pdes:\n",
    "    G = mats_glorot[f]\n",
    "    Df = mats_default[f]\n",
    "    Mpct = np.full_like(G, np.nan, dtype=float)\n",
    "    Mwins = np.full_like(G, False, dtype=bool)\n",
    "    for i in range(len(D)):\n",
    "        for j in range(len(W)):\n",
    "            g, dft = G[i, j], Df[i, j]\n",
    "            if np.isfinite(g) and np.isfinite(dft) and dft > 0:\n",
    "                val = (dft - g) / dft * 100.0\n",
    "                if val >= 0:\n",
    "                    Mpct[i, j] = val        # keep Glorot improvements\n",
    "                Mwins[i, j] = (g > dft)    # True if Default wins\n",
    "    mats_pct[f] = Mpct\n",
    "    mats_default_wins[f] = Mwins\n",
    "\n",
    "# colormap for heatmap\n",
    "cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "\n",
    "# colormap for line plots\n",
    "cmap_points = np.linspace(0, 1, 12)\n",
    "color_indices = [1, -2]\n",
    "colors_lp = [cmap(cmap_points[i]) for i in color_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers for training curves\n",
    "# -----------------------------\n",
    "def _stack_runs(runs):\n",
    "    runs = [np.asarray(r).ravel() for r in runs if r is not None]\n",
    "    if not runs:\n",
    "        return None\n",
    "    m = min(map(len, runs))\n",
    "    return np.stack([r[:m] for r in runs], axis=0).astype(float)\n",
    "\n",
    "def _set_log_ticks(ax, tick_fs, fixed_ticks=None):\n",
    "    ax.set_yscale(\"log\")\n",
    "    if fixed_ticks is None:\n",
    "        ax.yaxis.set_major_locator(LogLocator(base=10.0))\n",
    "        ax.yaxis.set_major_formatter(LogFormatterMathtext(base=10.0))\n",
    "        ax.yaxis.set_minor_locator(NullLocator())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "    else:\n",
    "        ax.yaxis.set_major_locator(FixedLocator(fixed_ticks))\n",
    "        ax.yaxis.set_minor_locator(NullLocator())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "    ax.tick_params(axis=\"y\", which=\"both\", labelsize=tick_fs)\n",
    "\n",
    "def _plot_mean_with_se(ax, runs, label, color):\n",
    "    arr = _stack_runs(runs)\n",
    "    if arr is None:\n",
    "        return None\n",
    "    n = arr.shape[0]\n",
    "    x = np.arange(arr.shape[1])\n",
    "    mean = arr.mean(axis=0)\n",
    "    se = (arr.std(axis=0, ddof=1) / np.sqrt(n)) if n > 1 else np.zeros_like(mean)\n",
    "\n",
    "    line, = ax.plot(x, mean, label=label, linewidth=2.0, color=color)\n",
    "    ax.fill_between(x, mean - se, mean + se, alpha=0.25, color=color, linewidth=0)\n",
    "    return line\n",
    "\n",
    "def _plot_two_arch_panels_for(func, ax_small, ax_big):\n",
    "    for arch, ax in zip(ARCHS, (ax_small, ax_big)):\n",
    "        _set_log_ticks(ax, TICK_FS)\n",
    "        runs_default = loss_dict.get(func, {}).get(arch, {}).get(\"default\", [])\n",
    "        runs_glorot  = loss_dict.get(func, {}).get(arch, {}).get(\"glorot\",  [])\n",
    "        h1 = _plot_mean_with_se(ax, runs_default, \"Default Initialization\", color=colors_lp[0])\n",
    "        h2 = _plot_mean_with_se(ax, runs_glorot,  \"Proposed Initialization\", color=colors_lp[1])\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "    return h1, h2\n",
    "\n",
    "# -----------------------------\n",
    "# Combined 2x3 figure\n",
    "# -----------------------------\n",
    "mosaic = [\n",
    "    [\"H_top\",  \".\", \"L_top_small\", \"L_top_big\"],\n",
    "    [\"H_bot\",  \".\", \"L_bot_small\", \"L_bot_big\"],\n",
    "]\n",
    "fig, axd = plt.subplot_mosaic(\n",
    "    mosaic,\n",
    "    figsize=(16, 8),\n",
    "    constrained_layout=True,\n",
    "    width_ratios=[1, 0.1, 1, 1]  # tweak 0.12 to widen/narrow the gap\n",
    ")\n",
    "\n",
    "# Rewire to your existing axes layout: axes[row, col] = [heatmap, line1, line2]\n",
    "axes = np.empty((2, 3), dtype=object)\n",
    "axes[0, 0] = axd[\"H_top\"]\n",
    "axes[0, 1] = axd[\"L_top_small\"]\n",
    "axes[0, 2] = axd[\"L_top_big\"]\n",
    "axes[1, 0] = axd[\"H_bot\"]\n",
    "axes[1, 1] = axd[\"L_bot_small\"]\n",
    "axes[1, 2] = axd[\"L_bot_big\"]\n",
    "\n",
    "im_last = None\n",
    "legend_handles = []\n",
    "\n",
    "for r, f in enumerate(pdes):\n",
    "    # heatmap in first column\n",
    "    ax = axes[r, 0]\n",
    "    Mpct = mats_pct[f]\n",
    "    wins_default = mats_default_wins[f]\n",
    "\n",
    "    im_last = ax.imshow(Mpct, cmap=cmap, vmin=0, vmax=100, origin=\"lower\", aspect=\"auto\")\n",
    "\n",
    "    red_mask = np.where(wins_default, 1.0, np.nan)\n",
    "    ax.imshow(red_mask, cmap=colors.ListedColormap([\"black\"]),\n",
    "              origin=\"lower\", aspect=\"auto\", alpha=0.85, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax.set_xticks(range(len(W))); ax.set_xticklabels(W, fontsize=TICK_FS)\n",
    "    ax.set_yticks(range(len(D))); ax.set_yticklabels(D, fontsize=TICK_FS)\n",
    "    if r == 1:\n",
    "        ax.set_xlabel(\"Hidden Layer Dimension\", fontsize=LABEL_FS)\n",
    "    ax.set_ylabel(\"Hidden Layers\", fontsize=LABEL_FS)\n",
    "\n",
    "    # line plots in columns 1 and 2\n",
    "    h1, h2 = _plot_two_arch_panels_for(f, axes[r, 1], axes[r, 2])\n",
    "    axes[r, 1].tick_params(axis=\"x\", labelsize=TICK_FS)\n",
    "    axes[r, 2].tick_params(axis=\"x\", labelsize=TICK_FS)\n",
    "    \n",
    "    axes[r, 1].set_xticks([0, 2500, 5000])\n",
    "    axes[r, 2].set_xticks([0, 2500, 5000])\n",
    "\n",
    "    if r == 0:\n",
    "        axes[r, 1].set_title(\"depth = 3, width = 4\", fontsize=TITLE_FS)\n",
    "        axes[r, 2].set_title(\"depth = 5, width = 16\",   fontsize=TITLE_FS)\n",
    "        axes[r, 1].set_ylabel(\"Training Loss\", fontsize=LABEL_FS)\n",
    "    \n",
    "    if r == 1:\n",
    "        axes[r, 1].set_xlabel(\"Training Iteration\", fontsize=LABEL_FS)\n",
    "        axes[r, 2].set_xlabel(\"Training Iteration\", fontsize=LABEL_FS)\n",
    "        axes[r, 1].set_ylabel(\"Training Loss\", fontsize=LABEL_FS, labelpad=15)\n",
    "\n",
    "    if not legend_handles:\n",
    "        legend_handles = [h for h in (h1, h2) if h is not None]\n",
    "\n",
    "# Far-right row labels\n",
    "axes[0, -1].annotate(\"Burgers\",\n",
    "                     xy=(1.08, 0.5), xycoords=\"axes fraction\",\n",
    "                     ha=\"left\", va=\"center\", rotation=90, fontsize=TITLE_FS)\n",
    "axes[1, -1].annotate(\"Helmholtz\",\n",
    "                     xy=(1.08, 0.5), xycoords=\"axes fraction\",\n",
    "                     ha=\"left\", va=\"center\", rotation=90, fontsize=TITLE_FS)\n",
    "\n",
    "# Horizontal colorbar below the heatmaps\n",
    "cbar = fig.colorbar(\n",
    "    im_last,\n",
    "    ax=[axes[0, 0], axes[1, 0]],\n",
    "    orientation=\"horizontal\",\n",
    "    fraction=0.045,   # adjust if needed\n",
    "    pad=0.10          # spacing from subplots\n",
    ")\n",
    "cbar.set_label(\"Initialization improvement\\nover Default (%)\", fontsize=LABEL_FS)\n",
    "cbar.ax.tick_params(labelsize=TICK_FS)\n",
    "\n",
    "# Legend centered under the two lineplot columns (right 2/3 of figure)\n",
    "if legend_handles:\n",
    "    fig.legend(\n",
    "        legend_handles,\n",
    "        [h.get_label() for h in legend_handles],\n",
    "        loc=\"lower center\",\n",
    "        ncol=2,\n",
    "        frameon=False,\n",
    "        fontsize=LEGEND_FS,\n",
    "        bbox_to_anchor=(0.67, 0.05)  # ~center of columns 1–2; tweak y if clipping\n",
    "    )\n",
    "\n",
    "# save + show\n",
    "plt.savefig(f\"{plots_dir}/small_pdes.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6f130-ff1d-40f1-9dc7-9fc0d04f6acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
