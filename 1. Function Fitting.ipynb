{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2e8de4-b906-4fee-9d0c-3229574c71b8",
   "metadata": {},
   "source": [
    "# Experiment 1: Function Fitting with Chebyshev Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4baaf-a3b3-47ad-a57b-4016ae9ec2c2",
   "metadata": {},
   "source": [
    "We perform a grid search over varying architectures, to get an understanding of the behavior for small, medium and large KANs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e1781-9514-460c-bd4d-954756b60985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "\n",
    "from src.functions import *\n",
    "from src.utils import generate_func_data, func_fit_step, func_fit_eval\n",
    "\n",
    "from src.kan import KAN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Define the experiment\n",
    "experiment_name = \"func_fit_D8\"\n",
    "results_file = os.path.join(results_dir, f\"{experiment_name}.csv\")\n",
    "\n",
    "# Define the file header\n",
    "header = \"function, width, depth, init_type, run, loss, l2\"\n",
    "\n",
    "# Check if the file exists and write the header if it doesn't\n",
    "if not os.path.exists(results_file):\n",
    "    with open(results_file, \"w\") as file:\n",
    "        file.write(header + \"\\n\")\n",
    "        \n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655960a1-288f-43be-9e39-d95c76fcbc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4c59f55-5b9b-4a4a-a968-1c00d06fcf5f",
   "metadata": {},
   "source": [
    "## Grid-Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212d91e-24c7-4d04-868c-1953092eb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the studied functions\n",
    "func_dict = {\"f1\": {'func': f1, 'dim': 1},\n",
    "             \"f2\": {'func': f2, 'dim': 2},\n",
    "             \"f3\": {'func': f3, 'dim': 2},\n",
    "             \"f4\": {'func': f4, 'dim': 3},\n",
    "             \"f5\": {'func': f5, 'dim': 5}}\n",
    "\n",
    "\n",
    "D = 8\n",
    "period_axes = None\n",
    "rff_std = None\n",
    "\n",
    "# Define the two types of initialization\n",
    "base_init = {'type': 'default'}\n",
    "glorot_init = {'type': 'glorot', 'gain': None, 'norm_pow': 0, 'distribution': 'uniform', 'sample_size': 10000}\n",
    "\n",
    "# Number of sampled points\n",
    "N = 5000\n",
    "\n",
    "# Number of training iterations\n",
    "num_epochs = 2000\n",
    "\n",
    "# Define simple optimizer\n",
    "opt_type = optax.adam(learning_rate=0.001)\n",
    "\n",
    "# Architecture settings\n",
    "widths = [2, 4, 8, 16, 32, 64]\n",
    "depths = [2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b269a-f2e2-40fc-a6cc-f473df372872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a75d7b70-6bc6-4501-8e9d-4f53ea2d7321",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76428312-c319-4121-a322-56bed8a15094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure\n",
    "for func_name in func_dict.keys():\n",
    "    print(f\"Running Experiments for {func_name} function.\")\n",
    "    function = func_dict[func_name]['func']\n",
    "    dim = func_dict[func_name]['dim']\n",
    "\n",
    "    # Generate data\n",
    "    x, y = generate_func_data(function, dim, N, seed)\n",
    "\n",
    "    # Split data, 80%-20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Model input/output\n",
    "    n_in, n_out = X_train.shape[1], y_train.shape[1]\n",
    "\n",
    "    # Grid search over depth size\n",
    "    for depth in depths:\n",
    "\n",
    "        # Grid search over width size\n",
    "        for width in widths:\n",
    "\n",
    "            # Discern between baseline initialization and Glorot-like initialization\n",
    "            for init_scheme in [base_init, glorot_init]:\n",
    "\n",
    "                type_init = init_scheme['type']\n",
    "            \n",
    "                print(f\"\\tTraining model with depth = {depth} and width = {width} ({type_init} init).\")\n",
    "\n",
    "                for run in [1, 2, 3, 4, 5]:\n",
    "\n",
    "                    model = KAN(n_in = n_in, n_out = n_out, n_hidden = width, num_layers = depth, D = D,\n",
    "                                init_scheme = init_scheme, period_axes = period_axes, rff_std = rff_std,\n",
    "                                seed = seed+run)\n",
    "            \n",
    "                    optimizer = nnx.Optimizer(model, opt_type)\n",
    "                \n",
    "                    # Train\n",
    "                    for epoch in range(num_epochs):\n",
    "                        train_loss = func_fit_step(model, optimizer, X_train, y_train)\n",
    "                \n",
    "                    # Evaluate\n",
    "                    y_pred = model(X_test)\n",
    "                    if func_name == \"f1\":\n",
    "                        res = 1000\n",
    "                    elif func_name in [\"f2\", \"f3\"]:\n",
    "                        res = 200\n",
    "                    elif func_name in [\"f4\"]:\n",
    "                        res = 30\n",
    "                    else:\n",
    "                        res = 10\n",
    "                    l2error = func_fit_eval(model, function, dim, resolution=res)\n",
    "                \n",
    "                    # Log results\n",
    "                    new_row = f\"{func_name}, {width}, {depth}, {type_init}, {run}, {train_loss}, {l2error}\"\n",
    "                                    \n",
    "                    # Append the row to the file\n",
    "                    with open(results_file, \"a\") as rfile:\n",
    "                        rfile.write(new_row + \"\\n\")\n",
    "\n",
    "                    print(f\"\\t\\t\\t{run}. Final loss: {train_loss:.2e} \\tRel. L2 Error: {l2error:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f72392-135d-4e66-865e-25fc66e0557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c9bc8c4-7965-4648-a348-1d543a329aa1",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's first determine how many times glorot overshadows default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c248e9c-fa22-4c0c-9bff-0bcf7f2a7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "agg_func = \"mean\"   # or \"mean\"\n",
    "comparison_mode = \"percent\"   # \"percent\" or \"logratio\"\n",
    "percent_clip_pct = 98         # robust clipping percentile for % heatmap\n",
    "eps = 1e-12                   # guard against division-by-zero\n",
    "\n",
    "# -----------------------------\n",
    "# Font sizes\n",
    "# -----------------------------\n",
    "FONT = {\n",
    "    \"title\": 20,\n",
    "    \"xlabel\": 18,\n",
    "    \"ylabel\": 18,\n",
    "    \"ticks\": 16,\n",
    "    \"cbar_label\": 18,\n",
    "    \"cbar_ticks\": 16,\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Load & reduce data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(results_file, sep=', ')\n",
    "\n",
    "df = df[df[\"depth\"] != 1]                      # exclude depth=1\n",
    "\n",
    "df_red = (\n",
    "    df.groupby([\"function\", \"width\", \"depth\", \"init_type\"])[\"l2\"]\n",
    "      .agg(agg_func)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_pivot = df_red.pivot(index=[\"function\",\"width\",\"depth\"],\n",
    "                        columns=\"init_type\", values=\"l2\").reset_index()\n",
    "\n",
    "df_pivot[\"width\"] = pd.to_numeric(df_pivot[\"width\"])\n",
    "df_pivot[\"depth\"] = pd.to_numeric(df_pivot[\"depth\"])\n",
    "W = sorted(df_pivot[\"width\"].unique().tolist())\n",
    "D = sorted(df_pivot[\"depth\"].unique().tolist())\n",
    "\n",
    "funcs = sorted(df_pivot[\"function\"].unique().tolist())\n",
    "W = sorted(df_pivot[\"width\"].unique().tolist())\n",
    "D = sorted(df_pivot[\"depth\"].unique().tolist())\n",
    "\n",
    "def build_matrix_for_col(f, col):\n",
    "    sub = df_pivot[df_pivot[\"function\"] == f]\n",
    "    M = np.full((len(D), len(W)), np.nan)\n",
    "    for i, d in enumerate(D):\n",
    "        for j, w in enumerate(W):\n",
    "            row = sub[(sub[\"width\"] == w) & (sub[\"depth\"] == d)]\n",
    "            if not row.empty and col in row:\n",
    "                M[i, j] = row.iloc[0][col]\n",
    "    return M\n",
    "\n",
    "mats_glorot  = {f: build_matrix_for_col(f, \"glorot\")  for f in funcs}\n",
    "mats_default = {f: build_matrix_for_col(f, \"default\") for f in funcs}\n",
    "\n",
    "# helper: LaTeX title\n",
    "def func_title(name: str) -> str:\n",
    "    if name == 'f1':\n",
    "        x = \"x\"\n",
    "    elif name in ['f2', 'f3']:\n",
    "        x = \"x_1, x_2\"\n",
    "    elif name == 'f4':\n",
    "        x = \"x_1, x_2, x_3\"\n",
    "    else:\n",
    "        x = \"\"\"x_1,\\dots,x_5\"\"\"\n",
    "    return rf\"$f_{{{name[1:]}}}({x})$\"\n",
    "\n",
    "mats_pct = {}\n",
    "mats_default_wins = {}\n",
    "for f in funcs:\n",
    "    G = mats_glorot[f]\n",
    "    Df = mats_default[f]\n",
    "    Mpct = np.full_like(G, np.nan, dtype=float)\n",
    "    Mwins = np.full_like(G, False, dtype=bool)\n",
    "    for i in range(len(D)):\n",
    "        for j in range(len(W)):\n",
    "            g, dft = G[i, j], Df[i, j]\n",
    "            if np.isfinite(g) and np.isfinite(dft) and dft > 0:\n",
    "                val = (dft - g) / dft * 100.0\n",
    "                if val >= 0:\n",
    "                    Mpct[i, j] = val        # keep Glorot improvements\n",
    "                Mwins[i, j] = (g > dft)    # True if Default wins\n",
    "    mats_pct[f] = Mpct\n",
    "    mats_default_wins[f] = Mwins\n",
    "\n",
    "# colormap\n",
    "cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "\n",
    "\n",
    "# -------- Figure: centered 3-over-2 mosaic --------\n",
    "fig = plt.figure(figsize=(16, 8), constrained_layout=True)\n",
    "gs = fig.add_gridspec(2, 6)\n",
    "\n",
    "slots = [(0, slice(0, 2)), (0, slice(2, 4)), (0, slice(4, 6)),\n",
    "         (1, slice(1, 3)), (1, slice(3, 5))]\n",
    "axes = [fig.add_subplot(gs[r, c]) for (r, c) in slots]\n",
    "\n",
    "im_last = None\n",
    "for ax, f in zip(axes, funcs):\n",
    "    Mpct = mats_pct[f]\n",
    "    wins_default = mats_default_wins[f]\n",
    "\n",
    "    # main heatmap (Glorot improvements, clipped 0–100 %)\n",
    "    im_last = ax.imshow(\n",
    "        Mpct,\n",
    "        cmap=cmap,\n",
    "        vmin=0, vmax=100,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "    )\n",
    "\n",
    "    # overlay solid black where Default wins\n",
    "    red_mask = np.where(wins_default, 1.0, np.nan)\n",
    "    ax.imshow(\n",
    "        red_mask,\n",
    "        cmap=colors.ListedColormap([\"black\"]),\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        alpha=0.85,\n",
    "        vmin=0.0, vmax=1.0,\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(range(len(W)))\n",
    "    ax.set_xticklabels(W, fontsize=FONT[\"ticks\"])\n",
    "    ax.set_yticks(range(len(D)))\n",
    "    ax.set_yticklabels(D, fontsize=FONT[\"ticks\"])\n",
    "    ax.set_xlabel(\"Hidden Layer Dimension\", fontsize=FONT[\"xlabel\"])\n",
    "    ax.set_ylabel(\"Hidden Layers\", fontsize=FONT[\"ylabel\"])\n",
    "    ax.set_title(func_title(f), fontsize=FONT[\"title\"])\n",
    "\n",
    "# single shared colorbar at the right\n",
    "cbar = fig.colorbar(im_last, ax=axes, shrink=0.85, location=\"right\", pad=0.02)\n",
    "cbar.set_label(\"Initialization improvement over Default (%)\", fontsize=FONT[\"cbar_label\"])\n",
    "cbar.ax.tick_params(labelsize=FONT[\"cbar_ticks\"])\n",
    "\n",
    "plt.savefig(f\"{plots_dir}/func_fit_heat.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a8463-0d8a-4544-b5b9-ce0f1d3cacb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc143ce-dab0-43a6-8248-8585c57e0ffc",
   "metadata": {},
   "source": [
    "## Loss Plots\n",
    "\n",
    "Given these results, we rerun some experiments to also derive plots for the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac16c6-f3c8-40a0-81a6-ff3d9451b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict = dict()\n",
    "\n",
    "# Procedure\n",
    "for func_name in func_dict.keys():\n",
    "    print(f\"Running Experiments for {func_name} function.\")\n",
    "    function = func_dict[func_name]['func']\n",
    "    dim = func_dict[func_name]['dim']\n",
    "\n",
    "    loss_dict[func_name] = dict()\n",
    "\n",
    "    # Generate data\n",
    "    x, y = generate_func_data(function, dim, N, seed)\n",
    "\n",
    "    # Split data, 80%-20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Model input/output\n",
    "    n_in, n_out = X_train.shape[1], y_train.shape[1]\n",
    "\n",
    "    # Different architectures\n",
    "    for arch_name, arch in zip([\"small\", \"big\"], [(4, 3), (16, 5)]):\n",
    "\n",
    "        loss_dict[func_name][arch_name] = dict()\n",
    "\n",
    "        width, depth = arch\n",
    "\n",
    "        # Discern between baseline initialization and Glorot-like initialization\n",
    "        for init_scheme in [base_init, glorot_init]:\n",
    "\n",
    "            type_init = init_scheme['type']\n",
    "\n",
    "            loss_dict[func_name][arch_name][type_init] = []\n",
    "            train_losses = jnp.zeros(num_epochs)\n",
    "        \n",
    "            print(f\"\\tTraining model with depth = {depth} and width = {width} ({type_init} init).\")\n",
    "\n",
    "            for run in [1, 2, 3, 4, 5]:\n",
    "\n",
    "                model = KAN(n_in = n_in, n_out = n_out, n_hidden = width, num_layers = depth, D = D,\n",
    "                            init_scheme = init_scheme, period_axes = period_axes, rff_std = rff_std,\n",
    "                            seed = seed+run)\n",
    "        \n",
    "                optimizer = nnx.Optimizer(model, opt_type)\n",
    "            \n",
    "                # Train\n",
    "                for epoch in range(num_epochs):\n",
    "                    train_loss = func_fit_step(model, optimizer, X_train, y_train)\n",
    "                    train_losses = train_losses.at[epoch].set(train_loss)\n",
    "            \n",
    "                # Evaluate\n",
    "                y_pred = model(X_test)\n",
    "                if func_name == \"f1\":\n",
    "                    res = 1000\n",
    "                elif func_name in [\"f2\", \"f3\"]:\n",
    "                    res = 200\n",
    "                elif func_name in [\"f4\"]:\n",
    "                    res = 30\n",
    "                else:\n",
    "                    res = 10\n",
    "                l2error = func_fit_eval(model, function, dim, resolution=res)\n",
    "\n",
    "                loss_dict[func_name][arch_name][type_init].append(train_losses)\n",
    "\n",
    "                print(f\"\\t\\t{run}. Final loss: {train_loss:.2e} \\tRel. L2 Error: {l2error:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83371ff-e56c-4152-9ee8-d4ef6d62fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "loss_file = os.path.join(results_dir, \"func_losses.pkl\")\n",
    "\n",
    "with open(loss_file, \"wb\") as f:\n",
    "    pickle.dump(loss_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7814c-35b8-43d6-8ac5-990b287125d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(results_dir, \"func_losses.pkl\"), \"rb\") as f:\n",
    "    loss_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b0c22-08dd-4ffb-8076-97c791e50a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (\n",
    "    LogLocator, LogFormatterMathtext,\n",
    "    FixedLocator, NullLocator, NullFormatter\n",
    ")\n",
    "\n",
    "# --- config you can tweak ---\n",
    "FUNCS = [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"]\n",
    "ARCHS = [\"small\", \"big\"]\n",
    "TITLE_FS = 22\n",
    "LABEL_FS = 20\n",
    "TICK_FS  = 18\n",
    "LEGEND_FS = 20\n",
    "\n",
    "cmap = plt.get_cmap(\"Spectral_r\")\n",
    "cmap_points = np.linspace(0, 1, 12)\n",
    "color_indices = [-2, 1]\n",
    "colors = [cmap(cmap_points[i]) for i in color_indices]\n",
    "\n",
    "def _func_title(name: str) -> str:\n",
    "    if name == 'f1':\n",
    "        x = \"x\"\n",
    "    elif name in ['f2', 'f3']:\n",
    "        x = \"x_1, x_2\"\n",
    "    elif name == 'f4':\n",
    "        x = \"x_1, x_2, x_3\"\n",
    "    else:\n",
    "        x = \"\"\"x_1,\\dots,x_5\"\"\"\n",
    "    return rf\"$f_{{{name[1:]}}}({x})$\"\n",
    "\n",
    "def _stack_runs(runs):\n",
    "    \"\"\"Stack a list of 1D arrays to shape (n_runs, n_epochs), trimming to min length if needed.\"\"\"\n",
    "    runs = [np.asarray(r).ravel() for r in runs if r is not None]\n",
    "    if not runs:\n",
    "        return None\n",
    "    m = min(map(len, runs))\n",
    "    return np.stack([r[:m] for r in runs], axis=0).astype(float)\n",
    "\n",
    "def _set_log_ticks(ax, tick_fs, fixed_ticks=None):\n",
    "    ax.set_yscale(\"log\")\n",
    "    if fixed_ticks is None:\n",
    "        # powers-of-10 only, no minor ticks\n",
    "        ax.yaxis.set_major_locator(LogLocator(base=10.0))\n",
    "        ax.yaxis.set_major_formatter(LogFormatterMathtext(base=10.0))\n",
    "        ax.yaxis.set_minor_locator(NullLocator())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "    else:\n",
    "        # exact ticks you want (e.g., [1e4]) and nothing else\n",
    "        ax.yaxis.set_major_locator(FixedLocator(fixed_ticks))\n",
    "        #ax.yaxis.set_major_formatter(LogFormatterMathtext(base=10.0))\n",
    "        ax.yaxis.set_minor_locator(NullLocator())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "    ax.tick_params(axis=\"y\", which=\"both\", labelsize=tick_fs)\n",
    "\n",
    "def _plot_mean_with_se(ax, runs, label, color):\n",
    "    \"\"\"Plot mean ± standard error (shaded), return the line handle (for legend).\"\"\"\n",
    "    arr = _stack_runs(runs)\n",
    "    if arr is None:\n",
    "        return None\n",
    "    n = arr.shape[0]\n",
    "    x = np.arange(arr.shape[1])\n",
    "    mean = arr.mean(axis=0)\n",
    "    # ddof=1 for sample std; guard n=1\n",
    "    se = (arr.std(axis=0, ddof=1) / np.sqrt(n)) if n > 1 else np.zeros_like(mean)\n",
    "\n",
    "    line, = ax.plot(x, mean, label=label, linewidth=2.0, color=color)\n",
    "    ax.fill_between(x, mean - se, mean + se, alpha=0.25, color=color, linewidth=0)\n",
    "    return line\n",
    "\n",
    "def plot_training_curves(loss_dict):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(18, 7), sharex=True, sharey=False, constrained_layout=True)\n",
    "\n",
    "    legend_handles = []\n",
    "\n",
    "    for col, func in enumerate(FUNCS):\n",
    "        for row, arch in enumerate(ARCHS):\n",
    "            ax = axes[row, col]\n",
    "            if row == 0 and col == 4:\n",
    "                _set_log_ticks(ax, TICK_FS, fixed_ticks=None)#[1.5e4])\n",
    "            elif row == 1 and col == 4:\n",
    "                _set_log_ticks(ax, TICK_FS, fixed_ticks=None)#[1e4])\n",
    "            else:\n",
    "                _set_log_ticks(ax, TICK_FS)\n",
    "                \n",
    "\n",
    "            # Pull runs safely; skip if missing\n",
    "            runs_default = loss_dict.get(func, {}).get(arch, {}).get(\"default\", [])\n",
    "            runs_glorot  = loss_dict.get(func, {}).get(arch, {}).get(\"glorot\",  [])\n",
    "\n",
    "            h1 = _plot_mean_with_se(ax, runs_default, \"Default Initialization\", color=colors[0])\n",
    "            h2 = _plot_mean_with_se(ax, runs_glorot,  \"Proposed Initialization\", color=colors[1])\n",
    "\n",
    "            # Titles only on top row\n",
    "            if row == 0:\n",
    "                ax.set_title(_func_title(func), fontsize=TITLE_FS)\n",
    "\n",
    "            # Axis labels on left and bottom edges\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(\"Training Loss\", fontsize=LABEL_FS)\n",
    "            if row == len(ARCHS) - 1:\n",
    "                ax.set_xlabel(\"Training Iteration\", fontsize=LABEL_FS)\n",
    "\n",
    "            ax.tick_params(labelsize=TICK_FS)\n",
    "\n",
    "            ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "            # Collect legend handles once (first subplot that has both)\n",
    "            if not legend_handles and (h1 is not None or h2 is not None):\n",
    "                legend_handles = [h for h in (h1, h2) if h is not None]\n",
    "\n",
    "    # annotate rows\n",
    "    axes[0, -1].annotate(\" 3 hidden layers\\n(dimension = 4)\",\n",
    "                         xy=(1.05, 0.5), xycoords=\"axes fraction\",\n",
    "                         ha=\"left\", va=\"center\", rotation=90, fontsize=LABEL_FS)\n",
    "    \n",
    "    axes[1, -1].annotate(\"  5 hidden layers\\n(dimension = 16)\",\n",
    "                         xy=(1.05, 0.5), xycoords=\"axes fraction\",\n",
    "                         ha=\"left\", va=\"center\", rotation=90, fontsize=LABEL_FS)\n",
    "\n",
    "    scale = 1e4\n",
    "    for r in [0, 1]:\n",
    "        ax = axes[r, 4]\n",
    "    \n",
    "        # switch to linear ticks, showing factors\n",
    "        yticks = [1.5e4, 1.6e4, 1.7e4, 1.8e4] if r == 0 else [1.0e4, 1.2e4, 1.4e4, 1.6e4, 1.8e4]\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.set_yticklabels([f\"{y/scale:.1f}\" for y in yticks], fontsize=TICK_FS)\n",
    "    \n",
    "        # add \"(×10^4)\" annotation above the y-axis\n",
    "        ax.set_ylabel(\"\")  # clear the original ylabel\n",
    "        ax.annotate(r\"$(\\times 10^{4})$\",\n",
    "                    xy=(0.08, 1.03), xycoords=\"axes fraction\",\n",
    "                    ha=\"right\", va=\"bottom\", fontsize=TICK_FS)\n",
    "\n",
    "    if legend_handles:\n",
    "        fig.legend(legend_handles, [h.get_label() for h in legend_handles],\n",
    "               loc=\"lower center\", ncol=2, frameon=False, fontsize=LEGEND_FS,\n",
    "               bbox_to_anchor=(0.5, -0.1))\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "# ---- call it ----\n",
    "fig, axes = plot_training_curves(loss_dict)\n",
    "plt.savefig(f\"{plots_dir}/func_fit_loss.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5d461-d346-4834-9e9a-3b1ab5c06489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5004c26-fe12-4913-8155-d81b417425bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
