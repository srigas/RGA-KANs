{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2e8de4-b906-4fee-9d0c-3229574c71b8",
   "metadata": {},
   "source": [
    "# Experiment 12.1: Poisson Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e1781-9514-460c-bd4d-954756b60985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "\n",
    "from src.utils import _get_adam, _get_pde_collocs, _get_ic_collocs, model_eval, count_params, _get_colloc_indices, grad_norm\n",
    "from src.utils import count_rga, count_pirate, count_pikan\n",
    "from src.wrappers import PoissonKAN, PoissonModel, PoissonPirate\n",
    "\n",
    "import numpy as np\n",
    "from jax import device_get\n",
    "\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "result_file = os.path.join(results_dir, \"benchmarks_poisson.pkl\")\n",
    "\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "RESULTS = dict()\n",
    "\n",
    "RESULTS[1] = dict()\n",
    "RESULTS[2] = dict()\n",
    "RESULTS[4] = dict()\n",
    "        \n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbd1ed-460a-4491-9476-d159167d1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_stats(RESULTS, model_idx, metric='l2'):\n",
    "    vals = []\n",
    "    runs = RESULTS.get(model_idx, {})\n",
    "    for i in (0, 1, 2):\n",
    "        try:\n",
    "            v = runs[i][metric]\n",
    "        except (KeyError, TypeError):\n",
    "            continue\n",
    "        v = np.array(v, dtype=float).squeeze()\n",
    "        vals.append(float(v))\n",
    "\n",
    "    if len(vals) == 0:\n",
    "        return np.nan, np.nan\n",
    "    if len(vals) == 1:\n",
    "        return float(vals[0]), np.nan\n",
    "\n",
    "    mean = float(np.mean(vals))\n",
    "    se = float(np.std(vals, ddof=1) / np.sqrt(len(vals)))\n",
    "    return mean, se\n",
    "\n",
    "def _collect_metric_vals(runs_dict, metric='l2', run_ids=(0,1,2)):\n",
    "    vals = []\n",
    "    for i in run_ids:\n",
    "        try:\n",
    "            v = runs_dict[i][metric]\n",
    "        except (KeyError, TypeError):\n",
    "            continue\n",
    "        v = np.array(v, dtype=float).squeeze()\n",
    "        vals.append(float(v))\n",
    "    return vals\n",
    "\n",
    "def pick_best_rgakan(RESULTS, metric='l2', configs=None, run_ids=(0,1,2)):\n",
    "    if configs is None:\n",
    "        configs = [(0,0), (0,1), (1,0), (1,1)]\n",
    "\n",
    "    # 1) Find best config by mean metric\n",
    "    config_stats = {}\n",
    "    for cfg in configs:\n",
    "        runs = RESULTS.get(cfg, {})\n",
    "        vals = _collect_metric_vals(runs, metric=metric, run_ids=run_ids)\n",
    "        if len(vals) == 0:\n",
    "            mean, se = np.inf, np.nan\n",
    "        elif len(vals) == 1:\n",
    "            mean, se = float(vals[0]), np.nan\n",
    "        else:\n",
    "            mean = float(np.mean(vals))\n",
    "            se = float(np.std(vals, ddof=1) / np.sqrt(len(vals)))\n",
    "        config_stats[cfg] = (mean, se)\n",
    "\n",
    "    # choose lowest mean; tie-break by smaller SE, then lexicographic cfg\n",
    "    best_config = min(configs, key=lambda c: (config_stats[c][0], np.nan_to_num(config_stats[c][1], nan=np.inf), c))\n",
    "    best_mean, best_se = config_stats[best_config]\n",
    "\n",
    "    # 2) Within best config, pick best run by lowest metric\n",
    "    runs = RESULTS.get(best_config, {})\n",
    "    best_run_idx, best_run_value = None, np.inf\n",
    "    for i in run_ids:\n",
    "        try:\n",
    "            v = runs[i][metric]\n",
    "            v = float(np.array(v, dtype=float).squeeze())\n",
    "        except (KeyError, TypeError, ValueError):\n",
    "            continue\n",
    "        if v < best_run_value:\n",
    "            best_run_value = v\n",
    "            best_run_idx = i\n",
    "\n",
    "    best_run_time = None\n",
    "    best_run_output = None\n",
    "    if best_run_idx is not None:\n",
    "        best_entry = runs.get(best_run_idx, {})\n",
    "        best_run_time = best_entry.get('time', None)\n",
    "        # 'output' was stored only for RGAKAN in your training loop\n",
    "        best_run_output = best_entry.get('output', None)\n",
    "        if best_run_output is not None:\n",
    "            best_run_output = np.array(best_run_output)\n",
    "\n",
    "    return {\n",
    "        'best_config': best_config,\n",
    "        'config_mean': best_mean,\n",
    "        'config_se': best_se,\n",
    "        'best_run_idx': best_run_idx,\n",
    "        'best_run_value': best_run_value,\n",
    "        'best_run_time': best_run_time,\n",
    "        'best_run_output': best_run_output,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa8bfd-1c9b-4e2d-a9fa-d4d830e47607",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def get_RAD_indices(model, collocs_pool, old_indices, l_E, l_E_pool):\n",
    "\n",
    "    # Apply updates from old indices to pool\n",
    "    updated_pool = l_E_pool.at[old_indices].set(l_E)\n",
    "\n",
    "    # Get full residuals\n",
    "    resids = pde_res(model, collocs_pool)\n",
    "    \n",
    "    # Multiply by RBA weights\n",
    "    w_resids = updated_pool * resids\n",
    "    \n",
    "    # Get absolute\n",
    "    wa_resids = jnp.abs(w_resids)\n",
    "\n",
    "    # Raise to power rad_a\n",
    "    ea = jnp.power(wa_resids, rad_a)\n",
    "    \n",
    "    # Divide by mean and add rad_c\n",
    "    px = (ea/jnp.mean(ea)) + rad_c\n",
    "    \n",
    "    # Normalize\n",
    "    px_norm = (px / jnp.sum(px))[:,0]\n",
    "\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=px_norm, seed=seed)\n",
    "\n",
    "    return sorted_indices, updated_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88abc93-3910-423d-a409-cfc39c9842f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "912ac241-e413-4c6c-bd97-5c0158839b6b",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b818a-7d1a-4c07-af79-494f3b7ac28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training epochs\n",
    "num_epochs = 100_000\n",
    "\n",
    "# Scheduler configurations\n",
    "learning_rate = 1e-3\n",
    "decay_steps = 2000\n",
    "decay_rate = 0.9\n",
    "warmup_steps = 1000\n",
    "\n",
    "# Define resampling parameters\n",
    "batch_size = 2**12\n",
    "f_resample = 2000\n",
    "rad_a = 1.0\n",
    "rad_c = 1.0\n",
    "\n",
    "# Define RBA parameters\n",
    "RBA_gamma = 0.999\n",
    "RBA_eta = 0.01\n",
    "\n",
    "# Define model parameters\n",
    "n_in = 2\n",
    "n_out = 1\n",
    "D = 5\n",
    "period_axes = None\n",
    "sine_D = 5\n",
    "init_scheme = {'type': 'glorot', 'gain': None, 'norm_pow': 0, 'distribution': 'uniform', 'sample_size': 10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411ce10-4781-450c-a416-7ed2899c8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "archs = ['RGA KAN', 'PirateNet', 'cPIKAN']\n",
    "\n",
    "arch_params = {'RGA KAN' : {'n_hidden' : 16, 'num_blocks' : 6},\n",
    "               'PirateNet' : {'n_hidden' : 36, 'num_blocks' : 4},\n",
    "               'cPIKAN' : {'n_hidden' : 18, 'num_layers' : 12}}\n",
    "\n",
    "print(\"Expected to train models with following number of parameters:\")\n",
    "\n",
    "rga_width = arch_params['RGA KAN']['n_hidden']\n",
    "rga_blocks = arch_params['RGA KAN']['num_blocks']\n",
    "rga_params = count_rga(n_in, period_axes, n_out, rga_width, rga_blocks, D, sine_D)\n",
    "print(f\"RGA KAN: {rga_params} parameters\")\n",
    "\n",
    "pirate_width = arch_params['PirateNet']['n_hidden']\n",
    "pirate_blocks = arch_params['PirateNet']['num_blocks']\n",
    "pirate_params = count_pirate(n_in, period_axes, n_out, pirate_width, pirate_blocks)\n",
    "print(f\"PirateNet: {pirate_params} parameters\")\n",
    "\n",
    "pikan_width = arch_params['cPIKAN']['n_hidden']\n",
    "pikan_depth = arch_params['cPIKAN']['num_layers']\n",
    "pikan_params = count_pikan(n_in, period_axes, n_out, pikan_width, pikan_depth, D)\n",
    "print(f\"cPIKAN: {pikan_params} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6179f-704d-43c7-8f2f-a361540e3ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fdc3451-f9ca-485a-86a2-f9284319a7a5",
   "metadata": {},
   "source": [
    "## $\\omega = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c308ce3-80b6-4a3f-a7f4-109697a46b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.equations import poisson_1_res as pde_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167086e-d086-454a-87f9-948c3f985908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocation points and ICs\n",
    "collocs_pool = _get_pde_collocs(ranges = [(-1,1), (-1,1)], sample_size = 400)\n",
    "\n",
    "# Reference solution\n",
    "ref = np.load('data/poisson_1.npz')\n",
    "refsol = jnp.array(ref['usol'])\n",
    "\n",
    "N_x, N_y = ref['usol'].shape\n",
    "x, y = ref['x'].flatten(), ref['y'].flatten()\n",
    "X, Y = jnp.meshgrid(x, y, indexing='ij')\n",
    "coords = jnp.hstack([X.flatten()[:, None], Y.flatten()[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044589a-5805-46e4-97d2-f1c5878771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, l_E, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Get new RBA weights\n",
    "    abs_res = jnp.abs(residuals)\n",
    "    l_E_new = (RBA_gamma*l_E) + (RBA_eta*abs_res/jnp.max(abs_res)) # shape (batch_size, 1)\n",
    "\n",
    "    # Multiply by RBA weights\n",
    "    w_resids = l_E_new * residuals # shape (batch_size, 1)\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(w_resids**2)\n",
    "\n",
    "    return weighted_loss, l_E_new\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, l_E):\n",
    "\n",
    "    # PDE loss\n",
    "    (loss, l_E_new), grads = nnx.value_and_grad(pde_loss, has_aux=True)(model, l_E, collocs)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, l_E_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7002a-da56-4e0c-8982-d9a40019f18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d40eba18-68ed-4dbb-aaee-9aa30f645f08",
   "metadata": {},
   "source": [
    "### cPIKAN / Pirate Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0187a66-1f68-4ecb-9e0a-0b1cf691a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in ['PirateNet', 'cPIKAN']:\n",
    "\n",
    "    RESULTS[1][arch] = dict()\n",
    "\n",
    "    n_hidden = arch_params[arch]['n_hidden']\n",
    "\n",
    "    if arch == 'PirateNet':\n",
    "        num_blocks = arch_params[arch]['num_blocks']\n",
    "        depth = int(3*num_blocks)\n",
    "    elif arch == 'cPIKAN':\n",
    "        num_layers = arch_params[arch]['num_layers']\n",
    "        depth = num_layers\n",
    "        \n",
    "    print(f\"Training {arch} with depth = {depth} and width = {n_hidden}.\")\n",
    "\n",
    "    for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "        RESULTS[1][arch][idx] = dict()\n",
    "        \n",
    "        # Initialize RBA weights - full pool\n",
    "        l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "    \n",
    "        # Get starting collocation points & RBA weights\n",
    "        sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "        \n",
    "        collocs = collocs_pool[sorted_indices]\n",
    "        l_E = l_E_pool[sorted_indices]\n",
    "        \n",
    "        # Get opt_type\n",
    "        opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "        # Define model\n",
    "        if arch == 'PirateNet':\n",
    "            model = PoissonPirate(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks,\n",
    "                                  alpha = 0.0, ref = None, period_axes = period_axes, rff_std = 1.0,\n",
    "                                  RWF={\"mean\": 1.0, \"std\": 0.1}, seed=seed+run)\n",
    "        elif arch == 'cPIKAN':\n",
    "            model = PoissonKAN(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_layers = num_layers, D = D,\n",
    "                               init_scheme = init_scheme, period_axes = period_axes, rff_std = None,\n",
    "                               seed = seed+run)\n",
    "\n",
    "        if idx == 0:\n",
    "            print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "\n",
    "        # Set optimizer\n",
    "        optimizer = nnx.Optimizer(model, opt_type)\n",
    "\n",
    "        tick = time.time()\n",
    "    \n",
    "        # Start training\n",
    "        for epoch in range(num_epochs):\n",
    "        \n",
    "            loss, l_E = train_step(model, optimizer, collocs, l_E)\n",
    "        \n",
    "            # Perform RAD\n",
    "            if (epoch != 0) and (epoch % f_resample == 0):\n",
    "    \n",
    "                # Get new indices after resampling\n",
    "                sorted_indices, l_E_pool = get_RAD_indices(model, collocs_pool, sorted_indices, l_E, l_E_pool)\n",
    "                # Set new batch of collocs and l_E\n",
    "                collocs = collocs_pool[sorted_indices]\n",
    "                l_E = l_E_pool[sorted_indices]\n",
    "\n",
    "        tack = time.time()\n",
    "        final_error = model_eval(model, coords, refsol)\n",
    "\n",
    "        print(f\"\\tRun = {idx}\\t L^2 = {final_error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "        RESULTS[1][arch][idx]['l2'] = np.asarray(device_get(final_error))\n",
    "        RESULTS[1][arch][idx]['loss'] = np.asarray(device_get(loss))\n",
    "        RESULTS[1][arch][idx]['time'] = (tack-tick)/num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc60aeb-591d-4250-9b02-bc3f8fe9583e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e91db7c-f0e2-4950-a4fe-542a3affdd7b",
   "metadata": {},
   "source": [
    "### RGA Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b920d74-2117-47b2-86cf-30ed783bee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = arch_params['RGA KAN']['num_blocks']\n",
    "n_hidden = arch_params['RGA KAN']['n_hidden']\n",
    "depth = int(2*num_blocks)\n",
    "\n",
    "print(f\"Training RGA KAN with depth = {depth} and width = {n_hidden}.\")\n",
    "\n",
    "for alpha in [0.0, 1.0]:\n",
    "    for beta in [0.0, 1.0]:\n",
    "\n",
    "        RESULTS[1][(alpha,beta)] = dict()\n",
    "        print(f\"Training for alpha = {alpha} and beta = {beta}.\")\n",
    "    \n",
    "        for idx, run in enumerate([0, 7, 42]):\n",
    "    \n",
    "            RESULTS[1][(alpha,beta)][idx] = dict()\n",
    "            \n",
    "            # Initialize RBA weights - full pool\n",
    "            l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "        \n",
    "            # Get starting collocation points & RBA weights\n",
    "            sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "            \n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "            l_E = l_E_pool[sorted_indices]\n",
    "            \n",
    "            # Get opt_type\n",
    "            opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "    \n",
    "            # Define model\n",
    "            model = PoissonModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                 init_scheme = init_scheme, alpha = alpha, beta = beta, ref = None,\n",
    "                                 period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "    \n",
    "            if idx == 0:\n",
    "                print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "            # Set optimizer\n",
    "            optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "            tick = time.time()\n",
    "        \n",
    "            # Start training\n",
    "            for epoch in range(num_epochs):\n",
    "            \n",
    "                loss, l_E = train_step(model, optimizer, collocs, l_E)\n",
    "            \n",
    "                # Perform RAD\n",
    "                if (epoch != 0) and (epoch % f_resample == 0):\n",
    "        \n",
    "                    # Get new indices after resampling\n",
    "                    sorted_indices, l_E_pool = get_RAD_indices(model, collocs_pool, sorted_indices, l_E, l_E_pool)\n",
    "                    # Set new batch of collocs and l_E\n",
    "                    collocs = collocs_pool[sorted_indices]\n",
    "                    l_E = l_E_pool[sorted_indices]\n",
    "    \n",
    "            tack = time.time()\n",
    "            final_output = model(coords).reshape(refsol.shape)\n",
    "            final_error = model_eval(model, coords, refsol)\n",
    "    \n",
    "            print(f\"\\tRun = {idx}\\t L^2 = {final_error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "    \n",
    "            RESULTS[1][(alpha,beta)][idx]['l2'] = np.asarray(device_get(final_error))\n",
    "            RESULTS[1][(alpha,beta)][idx]['loss'] = np.asarray(device_get(loss))\n",
    "            RESULTS[1][(alpha,beta)][idx]['time'] = (tack-tick)/num_epochs\n",
    "            RESULTS[1][(alpha,beta)][idx]['output'] = np.asarray(device_get(final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32876f9-4bb0-4736-9234-93a1adaa1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024eacef-1d71-4de6-ab80-12a51bace9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fae00e-2217-4ee5-8be2-90507b4f4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(result_file, \"rb\") as f:\n",
    "    RESULTS = pickle.load(f)\n",
    "\n",
    "this_res = RESULTS[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8ea96-d233-4486-bb2e-0a9110f3b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTS\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "m, s = metric_stats(this_res, 'PirateNet', 'l2')\n",
    "tt, _ = metric_stats(this_res, 'PirateNet', 'time')\n",
    "print(f\"PirateNet:\\t\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, 'cPIKAN', 'l2')\n",
    "tt, _ = metric_stats(this_res, 'cPIKAN', 'time')\n",
    "print(f\"cPIKAN:\\t\\t\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (0,0), 'l2')\n",
    "tt, _ = metric_stats(this_res, (0,0), 'time')\n",
    "print(f\"RGAKAN (α = 0, β = 0):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (1,0), 'l2')\n",
    "tt, _ = metric_stats(this_res, (1,0), 'time')\n",
    "print(f\"RGAKAN (α = 1, β = 0):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (0,1), 'l2')\n",
    "tt, _ = metric_stats(this_res, (0,1), 'time')\n",
    "print(f\"RGAKAN (α = 0, β = 1):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (1,1), 'l2')\n",
    "tt, _ = metric_stats(this_res, (1,1), 'time')\n",
    "print(f\"RGAKAN (α = 1, β = 1):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "m, s = metric_stats(this_res, 'PirateNet', 'loss')\n",
    "print(f\"PirateNet:\\t\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, 'cPIKAN', 'loss')\n",
    "print(f\"cPIKAN:\\t\\t\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (0,0), 'loss')\n",
    "print(f\"RGAKAN (α = 0, β = 0):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (1,0), 'loss')\n",
    "print(f\"RGAKAN (α = 1, β = 0):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (0,1), 'loss')\n",
    "print(f\"RGAKAN (α = 0, β = 1):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (1,1), 'loss')\n",
    "print(f\"RGAKAN (α = 1, β = 1):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3de3de-e753-4810-b7ba-ae1b04388e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = pick_best_rgakan(this_res, metric='l2')\n",
    "a, b = res_1['best_config']\n",
    "print(f\"The lowest average L^2 error is obtained for alpha = {a} and beta = {b}.\")\n",
    "print(f\"Among the runs with this configuration, the lowest L^2 error is {res_1['best_run_value']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe355013-9c94-4440-bdee-78459efd3b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87796f61-d970-4a99-bec9-3c8bfa7631de",
   "metadata": {},
   "source": [
    "## $\\omega = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476d69b-ae37-4bdc-b3a2-994065a87fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.equations import poisson_2_res as pde_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa80327-56c8-4338-a8b5-1c2f27a4c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocation points and ICs\n",
    "collocs_pool = _get_pde_collocs(ranges = [(-1,1), (-1,1)], sample_size = 400)\n",
    "\n",
    "# Reference solution\n",
    "ref = np.load('data/poisson_2.npz')\n",
    "refsol = jnp.array(ref['usol'])\n",
    "\n",
    "N_x, N_y = ref['usol'].shape\n",
    "x, y = ref['x'].flatten(), ref['y'].flatten()\n",
    "X, Y = jnp.meshgrid(x, y, indexing='ij')\n",
    "coords = jnp.hstack([X.flatten()[:, None], Y.flatten()[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b735c-7da7-424b-9bb5-ee280162ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, l_E, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Get new RBA weights\n",
    "    abs_res = jnp.abs(residuals)\n",
    "    l_E_new = (RBA_gamma*l_E) + (RBA_eta*abs_res/jnp.max(abs_res)) # shape (batch_size, 1)\n",
    "\n",
    "    # Multiply by RBA weights\n",
    "    w_resids = l_E_new * residuals # shape (batch_size, 1)\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(w_resids**2)\n",
    "\n",
    "    return weighted_loss, l_E_new\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, l_E):\n",
    "\n",
    "    # PDE loss\n",
    "    (loss, l_E_new), grads = nnx.value_and_grad(pde_loss, has_aux=True)(model, l_E, collocs)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, l_E_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7cd19-42b3-49a2-b866-0ae09bebfc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1044d9a-8483-43f5-8750-0bb624db8244",
   "metadata": {},
   "source": [
    "### cPIKAN / Pirate Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ded14-10ed-4f2c-8479-d20167d578c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in ['PirateNet', 'cPIKAN']:\n",
    "\n",
    "    RESULTS[2][arch] = dict()\n",
    "\n",
    "    n_hidden = arch_params[arch]['n_hidden']\n",
    "\n",
    "    if arch == 'PirateNet':\n",
    "        num_blocks = arch_params[arch]['num_blocks']\n",
    "        depth = int(3*num_blocks)\n",
    "    elif arch == 'cPIKAN':\n",
    "        num_layers = arch_params[arch]['num_layers']\n",
    "        depth = num_layers\n",
    "        \n",
    "    print(f\"Training {arch} with depth = {depth} and width = {n_hidden}.\")\n",
    "\n",
    "    for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "        RESULTS[2][arch][idx] = dict()\n",
    "        \n",
    "        # Initialize RBA weights - full pool\n",
    "        l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "    \n",
    "        # Get starting collocation points & RBA weights\n",
    "        sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "        \n",
    "        collocs = collocs_pool[sorted_indices]\n",
    "        l_E = l_E_pool[sorted_indices]\n",
    "        \n",
    "        # Get opt_type\n",
    "        opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "        # Define model\n",
    "        if arch == 'PirateNet':\n",
    "            model = PoissonPirate(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks,\n",
    "                                  alpha = 0.0, ref = None, period_axes = period_axes, rff_std = 1.0,\n",
    "                                  RWF={\"mean\": 1.0, \"std\": 0.1}, seed=seed+run)\n",
    "        elif arch == 'cPIKAN':\n",
    "            model = PoissonKAN(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_layers = num_layers, D = D,\n",
    "                               init_scheme = init_scheme, period_axes = period_axes, rff_std = None,\n",
    "                               seed = seed+run)\n",
    "\n",
    "        if idx == 0:\n",
    "            print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "\n",
    "        # Set optimizer\n",
    "        optimizer = nnx.Optimizer(model, opt_type)\n",
    "\n",
    "        tick = time.time()\n",
    "    \n",
    "        # Start training\n",
    "        for epoch in range(num_epochs):\n",
    "        \n",
    "            loss, l_E = train_step(model, optimizer, collocs, l_E)\n",
    "        \n",
    "            # Perform RAD\n",
    "            if (epoch != 0) and (epoch % f_resample == 0):\n",
    "    \n",
    "                # Get new indices after resampling\n",
    "                sorted_indices, l_E_pool = get_RAD_indices(model, collocs_pool, sorted_indices, l_E, l_E_pool)\n",
    "                # Set new batch of collocs and l_E\n",
    "                collocs = collocs_pool[sorted_indices]\n",
    "                l_E = l_E_pool[sorted_indices]\n",
    "\n",
    "        tack = time.time()\n",
    "        final_error = model_eval(model, coords, refsol)\n",
    "\n",
    "        print(f\"\\tRun = {idx}\\t L^2 = {final_error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "        RESULTS[2][arch][idx]['l2'] = np.asarray(device_get(final_error))\n",
    "        RESULTS[2][arch][idx]['loss'] = np.asarray(device_get(loss))\n",
    "        RESULTS[2][arch][idx]['time'] = (tack-tick)/num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5843366-e97e-4d65-b19d-ca9c382e4d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "986147ef-eae0-4917-8dae-1f6a469cc946",
   "metadata": {},
   "source": [
    "### RGA Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf8cae-7a17-49c5-abfd-a9cbfe5bf234",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = arch_params['RGA KAN']['num_blocks']\n",
    "n_hidden = arch_params['RGA KAN']['n_hidden']\n",
    "depth = int(2*num_blocks)\n",
    "\n",
    "print(f\"Training RGA KAN with depth = {depth} and width = {n_hidden}.\")\n",
    "\n",
    "for alpha in [0.0, 1.0]:\n",
    "    for beta in [0.0, 1.0]:\n",
    "\n",
    "        RESULTS[2][(alpha,beta)] = dict()\n",
    "        print(f\"Training for alpha = {alpha} and beta = {beta}.\")\n",
    "    \n",
    "        for idx, run in enumerate([0, 7, 42]):\n",
    "    \n",
    "            RESULTS[2][(alpha,beta)][idx] = dict()\n",
    "            \n",
    "            # Initialize RBA weights - full pool\n",
    "            l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "        \n",
    "            # Get starting collocation points & RBA weights\n",
    "            sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "            \n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "            l_E = l_E_pool[sorted_indices]\n",
    "            \n",
    "            # Get opt_type\n",
    "            opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "    \n",
    "            # Define model\n",
    "            model = PoissonModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                 init_scheme = init_scheme, alpha = alpha, beta = beta, ref = None,\n",
    "                                 period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "    \n",
    "            if idx == 0:\n",
    "                print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "            # Set optimizer\n",
    "            optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "            tick = time.time()\n",
    "        \n",
    "            # Start training\n",
    "            for epoch in range(num_epochs):\n",
    "            \n",
    "                loss, l_E = train_step(model, optimizer, collocs, l_E)\n",
    "            \n",
    "                # Perform RAD\n",
    "                if (epoch != 0) and (epoch % f_resample == 0):\n",
    "        \n",
    "                    # Get new indices after resampling\n",
    "                    sorted_indices, l_E_pool = get_RAD_indices(model, collocs_pool, sorted_indices, l_E, l_E_pool)\n",
    "                    # Set new batch of collocs and l_E\n",
    "                    collocs = collocs_pool[sorted_indices]\n",
    "                    l_E = l_E_pool[sorted_indices]\n",
    "    \n",
    "            tack = time.time()\n",
    "            final_output = model(coords).reshape(refsol.shape)\n",
    "            final_error = model_eval(model, coords, refsol)\n",
    "    \n",
    "            print(f\"\\tRun = {idx}\\t L^2 = {final_error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "    \n",
    "            RESULTS[2][(alpha,beta)][idx]['l2'] = np.asarray(device_get(final_error))\n",
    "            RESULTS[2][(alpha,beta)][idx]['loss'] = np.asarray(device_get(loss))\n",
    "            RESULTS[2][(alpha,beta)][idx]['time'] = (tack-tick)/num_epochs\n",
    "            RESULTS[2][(alpha,beta)][idx]['output'] = np.asarray(device_get(final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b3718-2a50-4ece-9418-347bf52a86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 2\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6055f-9449-4984-b7c5-dc4f84a341fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d99c0c-2734-4822-9c53-d7bb1ddc9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(result_file, \"rb\") as f:\n",
    "    RESULTS = pickle.load(f)\n",
    "\n",
    "this_res = RESULTS[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9dd7d1-9c25-4943-a341-651c765e76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTS\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "m, s = metric_stats(this_res, 'PirateNet', 'l2')\n",
    "tt, _ = metric_stats(this_res, 'PirateNet', 'time')\n",
    "print(f\"PirateNet:\\t\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, 'cPIKAN', 'l2')\n",
    "tt, _ = metric_stats(this_res, 'cPIKAN', 'time')\n",
    "print(f\"cPIKAN:\\t\\t\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (0,0), 'l2')\n",
    "tt, _ = metric_stats(this_res, (0,0), 'time')\n",
    "print(f\"RGAKAN (α = 0, β = 0):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (1,0), 'l2')\n",
    "tt, _ = metric_stats(this_res, (1,0), 'time')\n",
    "print(f\"RGAKAN (α = 1, β = 0):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (0,1), 'l2')\n",
    "tt, _ = metric_stats(this_res, (0,1), 'time')\n",
    "print(f\"RGAKAN (α = 0, β = 1):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (1,1), 'l2')\n",
    "tt, _ = metric_stats(this_res, (1,1), 'time')\n",
    "print(f\"RGAKAN (α = 1, β = 1):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "m, s = metric_stats(this_res, 'PirateNet', 'loss')\n",
    "print(f\"PirateNet:\\t\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, 'cPIKAN', 'loss')\n",
    "print(f\"cPIKAN:\\t\\t\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (0,0), 'loss')\n",
    "print(f\"RGAKAN (α = 0, β = 0):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (1,0), 'loss')\n",
    "print(f\"RGAKAN (α = 1, β = 0):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (0,1), 'loss')\n",
    "print(f\"RGAKAN (α = 0, β = 1):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (1,1), 'loss')\n",
    "print(f\"RGAKAN (α = 1, β = 1):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979465ed-28ca-4625-9a59-b60c5428e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = pick_best_rgakan(this_res, metric='l2')\n",
    "a, b = res_2['best_config']\n",
    "print(f\"The lowest average L^2 error is obtained for alpha = {a} and beta = {b}.\")\n",
    "print(f\"Among the runs with this configuration, the lowest L^2 error is {res_2['best_run_value']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac51945-384d-428d-8eac-0e73020ee855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a99e5ae9-cd7d-4bab-a208-9e6552b24521",
   "metadata": {},
   "source": [
    "## $\\omega = 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571749d1-494a-409d-841a-565d98911475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.equations import poisson_4_res as pde_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4608da4-6fb0-4a55-872a-5d5ff2e3e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocation points and ICs\n",
    "collocs_pool = _get_pde_collocs(ranges = [(-1,1), (-1,1)], sample_size = 400)\n",
    "\n",
    "# Reference solution\n",
    "ref = np.load('data/poisson_4.npz')\n",
    "refsol = jnp.array(ref['usol'])\n",
    "\n",
    "N_x, N_y = ref['usol'].shape\n",
    "x, y = ref['x'].flatten(), ref['y'].flatten()\n",
    "X, Y = jnp.meshgrid(x, y, indexing='ij')\n",
    "coords = jnp.hstack([X.flatten()[:, None], Y.flatten()[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35738820-cd80-4b09-bf07-d2e99617fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, l_E, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Get new RBA weights\n",
    "    abs_res = jnp.abs(residuals)\n",
    "    l_E_new = (RBA_gamma*l_E) + (RBA_eta*abs_res/jnp.max(abs_res)) # shape (batch_size, 1)\n",
    "\n",
    "    # Multiply by RBA weights\n",
    "    w_resids = l_E_new * residuals # shape (batch_size, 1)\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(w_resids**2)\n",
    "\n",
    "    return weighted_loss, l_E_new\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, l_E):\n",
    "\n",
    "    # PDE loss\n",
    "    (loss, l_E_new), grads = nnx.value_and_grad(pde_loss, has_aux=True)(model, l_E, collocs)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, l_E_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfda0c-b60a-46da-8740-fd3483054cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44ad0b33-e7a8-4b33-ba62-d7e68a4561f3",
   "metadata": {},
   "source": [
    "### cPIKAN / Pirate Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a6f83-b3e9-46d8-9c2c-bb0a645fbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for arch in ['PirateNet', 'cPIKAN']:\n",
    "\n",
    "    RESULTS[4][arch] = dict()\n",
    "\n",
    "    n_hidden = arch_params[arch]['n_hidden']\n",
    "\n",
    "    if arch == 'PirateNet':\n",
    "        num_blocks = arch_params[arch]['num_blocks']\n",
    "        depth = int(3*num_blocks)\n",
    "    elif arch == 'cPIKAN':\n",
    "        num_layers = arch_params[arch]['num_layers']\n",
    "        depth = num_layers\n",
    "        \n",
    "    print(f\"Training {arch} with depth = {depth} and width = {n_hidden}.\")\n",
    "\n",
    "    for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "        RESULTS[4][arch][idx] = dict()\n",
    "        \n",
    "        # Initialize RBA weights - full pool\n",
    "        l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "    \n",
    "        # Get starting collocation points & RBA weights\n",
    "        sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "        \n",
    "        collocs = collocs_pool[sorted_indices]\n",
    "        l_E = l_E_pool[sorted_indices]\n",
    "        \n",
    "        # Get opt_type\n",
    "        opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "        # Define model\n",
    "        if arch == 'PirateNet':\n",
    "            model = PoissonPirate(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks,\n",
    "                                  alpha = 0.0, ref = None, period_axes = period_axes, rff_std = 1.0,\n",
    "                                  RWF={\"mean\": 1.0, \"std\": 0.1}, seed=seed+run)\n",
    "        elif arch == 'cPIKAN':\n",
    "            model = PoissonKAN(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_layers = num_layers, D = D,\n",
    "                               init_scheme = init_scheme, period_axes = period_axes, rff_std = None,\n",
    "                               seed = seed+run)\n",
    "\n",
    "        if idx == 0:\n",
    "            print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "\n",
    "        # Set optimizer\n",
    "        optimizer = nnx.Optimizer(model, opt_type)\n",
    "\n",
    "        tick = time.time()\n",
    "    \n",
    "        # Start training\n",
    "        for epoch in range(num_epochs):\n",
    "        \n",
    "            loss, l_E = train_step(model, optimizer, collocs, l_E)\n",
    "        \n",
    "            # Perform RAD\n",
    "            if (epoch != 0) and (epoch % f_resample == 0):\n",
    "    \n",
    "                # Get new indices after resampling\n",
    "                sorted_indices, l_E_pool = get_RAD_indices(model, collocs_pool, sorted_indices, l_E, l_E_pool)\n",
    "                # Set new batch of collocs and l_E\n",
    "                collocs = collocs_pool[sorted_indices]\n",
    "                l_E = l_E_pool[sorted_indices]\n",
    "\n",
    "        tack = time.time()\n",
    "        final_error = model_eval(model, coords, refsol)\n",
    "\n",
    "        print(f\"\\tRun = {idx}\\t L^2 = {final_error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "        RESULTS[4][arch][idx]['l2'] = np.asarray(device_get(final_error))\n",
    "        RESULTS[4][arch][idx]['loss'] = np.asarray(device_get(loss))\n",
    "        RESULTS[4][arch][idx]['time'] = (tack-tick)/num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885c7e5-f6a7-4eb9-9be3-6b5a2903d36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b812069f-00b6-4e71-bf2b-fbb5102fa9ff",
   "metadata": {},
   "source": [
    "### RGA Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39c65e-1dc6-41f0-b1b6-9c4dc17860bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = arch_params['RGA KAN']['num_blocks']\n",
    "n_hidden = arch_params['RGA KAN']['n_hidden']\n",
    "depth = int(2*num_blocks)\n",
    "\n",
    "print(f\"Training RGA KAN with depth = {depth} and width = {n_hidden}.\")\n",
    "\n",
    "for alpha in [0.0, 1.0]:\n",
    "    for beta in [0.0, 1.0]:\n",
    "\n",
    "        RESULTS[4][(alpha,beta)] = dict()\n",
    "        print(f\"Training for alpha = {alpha} and beta = {beta}.\")\n",
    "    \n",
    "        for idx, run in enumerate([0, 7, 42]):\n",
    "    \n",
    "            RESULTS[4][(alpha,beta)][idx] = dict()\n",
    "            \n",
    "            # Initialize RBA weights - full pool\n",
    "            l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "        \n",
    "            # Get starting collocation points & RBA weights\n",
    "            sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "            \n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "            l_E = l_E_pool[sorted_indices]\n",
    "            \n",
    "            # Get opt_type\n",
    "            opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "    \n",
    "            # Define model\n",
    "            model = PoissonModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                 init_scheme = init_scheme, alpha = alpha, beta = beta, ref = None,\n",
    "                                 period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "    \n",
    "            if idx == 0:\n",
    "                print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "            # Set optimizer\n",
    "            optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "            tick = time.time()\n",
    "        \n",
    "            # Start training\n",
    "            for epoch in range(num_epochs):\n",
    "            \n",
    "                loss, l_E = train_step(model, optimizer, collocs, l_E)\n",
    "            \n",
    "                # Perform RAD\n",
    "                if (epoch != 0) and (epoch % f_resample == 0):\n",
    "        \n",
    "                    # Get new indices after resampling\n",
    "                    sorted_indices, l_E_pool = get_RAD_indices(model, collocs_pool, sorted_indices, l_E, l_E_pool)\n",
    "                    # Set new batch of collocs and l_E\n",
    "                    collocs = collocs_pool[sorted_indices]\n",
    "                    l_E = l_E_pool[sorted_indices]\n",
    "    \n",
    "            tack = time.time()\n",
    "            final_output = model(coords).reshape(refsol.shape)\n",
    "            final_error = model_eval(model, coords, refsol)\n",
    "    \n",
    "            print(f\"\\tRun = {idx}\\t L^2 = {final_error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "    \n",
    "            RESULTS[4][(alpha,beta)][idx]['l2'] = np.asarray(device_get(final_error))\n",
    "            RESULTS[4][(alpha,beta)][idx]['loss'] = np.asarray(device_get(loss))\n",
    "            RESULTS[4][(alpha,beta)][idx]['time'] = (tack-tick)/num_epochs\n",
    "            RESULTS[4][(alpha,beta)][idx]['output'] = np.asarray(device_get(final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634e480-e05c-4549-a7f8-b41a7f8f8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 3\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7725786-a3ac-436b-add0-a12bf9849243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4099ba-b9cd-492b-85ee-9a77b5243a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(result_file, \"rb\") as f:\n",
    "    RESULTS = pickle.load(f)\n",
    "\n",
    "this_res = RESULTS[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a349090-64ac-4c19-8baf-2168274dc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTS\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "m, s = metric_stats(this_res, 'PirateNet', 'l2')\n",
    "tt, _ = metric_stats(this_res, 'PirateNet', 'time')\n",
    "print(f\"PirateNet:\\t\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, 'cPIKAN', 'l2')\n",
    "tt, _ = metric_stats(this_res, 'cPIKAN', 'time')\n",
    "print(f\"cPIKAN:\\t\\t\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (0,0), 'l2')\n",
    "tt, _ = metric_stats(this_res, (0,0), 'time')\n",
    "print(f\"RGAKAN (α = 0, β = 0):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (1,0), 'l2')\n",
    "tt, _ = metric_stats(this_res, (1,0), 'time')\n",
    "print(f\"RGAKAN (α = 1, β = 0):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (0,1), 'l2')\n",
    "tt, _ = metric_stats(this_res, (0,1), 'time')\n",
    "print(f\"RGAKAN (α = 0, β = 1):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "m, s = metric_stats(this_res, (1,1), 'l2')\n",
    "tt, _ = metric_stats(this_res, (1,1), 'time')\n",
    "print(f\"RGAKAN (α = 1, β = 1):\\t L^2 = {m:.3e}\\t Error = {s:.3e}\\t Time = {tt*1000:.2f} ms.\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "m, s = metric_stats(this_res, 'PirateNet', 'loss')\n",
    "print(f\"PirateNet:\\t\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, 'cPIKAN', 'loss')\n",
    "print(f\"cPIKAN:\\t\\t\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (0,0), 'loss')\n",
    "print(f\"RGAKAN (α = 0, β = 0):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (1,0), 'loss')\n",
    "print(f\"RGAKAN (α = 1, β = 0):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (0,1), 'loss')\n",
    "print(f\"RGAKAN (α = 0, β = 1):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")\n",
    "m, s = metric_stats(this_res, (1,1), 'loss')\n",
    "print(f\"RGAKAN (α = 1, β = 1):\\t Loss = {m:.3e}\\t Error = {s:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097856f-8ae5-4fee-a4e6-62a2e1fcef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_4 = pick_best_rgakan(this_res, metric='l2')\n",
    "a, b = res_4['best_config']\n",
    "print(f\"The lowest average L^2 error is obtained for alpha = {a} and beta = {b}.\")\n",
    "print(f\"Among the runs with this configuration, the lowest L^2 error is {res_4['best_run_value']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b865783-a628-49e4-83f8-1fee9fd63d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47cd17bc-4e10-4b87-8e2f-6c13271b2f57",
   "metadata": {},
   "source": [
    "## Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db025d-a59d-4ec7-812a-725f7e3b7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = np.load('data/poisson_1.npz')\n",
    "refsol1 = jnp.array(ref['usol'])\n",
    "\n",
    "ref = np.load('data/poisson_2.npz')\n",
    "refsol2 = jnp.array(ref['usol'])\n",
    "\n",
    "ref = np.load('data/poisson_4.npz')\n",
    "refsol4 = jnp.array(ref['usol'])\n",
    "\n",
    "pred1 = res_1['best_run_output']\n",
    "pred2 = res_2['best_run_output']\n",
    "pred4 = res_4['best_run_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6092e57-2ccf-4f54-ac27-3d16ba1b96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import ticker\n",
    "\n",
    "LABEL_FS = 16\n",
    "TITLE_FS = 18\n",
    "TICK_FS = 14\n",
    "CBAR_FS = 16\n",
    "\n",
    "def plot_pred_ref_diff_grid(u_preds, refsols, x, t, save_fig=False,\n",
    "                            clim_pred=None, clim_ref=None, clim_diff=None,\n",
    "                            row_titles=None, fig_name=\"final_poisson.pdf\"):\n",
    "\n",
    "    # normalize inputs\n",
    "    u_preds  = [np.array(u) for u in u_preds]\n",
    "    refsols  = [np.array(r) for r in refsols]\n",
    "    assert len(u_preds) == len(refsols), \"u_preds and refsols must have same length\"\n",
    "    nrows = len(u_preds)\n",
    "\n",
    "    extent = [np.min(x), np.max(x), np.min(t), np.max(t)]\n",
    "    cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "\n",
    "    def _clim_for(clim, i):\n",
    "        if clim is None:\n",
    "            return None\n",
    "        # per-row list/tuple of tuples\n",
    "        if isinstance(clim, (list, tuple)) and len(clim) == nrows and isinstance(clim[0], (list, tuple)):\n",
    "            return clim[i]\n",
    "        # single tuple applied to all rows\n",
    "        if isinstance(clim, (list, tuple)) and len(clim) == 2 and np.isscalar(clim[0]) and np.isscalar(clim[1]):\n",
    "            return clim\n",
    "        return None\n",
    "\n",
    "    fig, axs = plt.subplots(nrows, 3, figsize=(14, 2.5*nrows), constrained_layout=False)\n",
    "    if nrows == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)  # unify indexing\n",
    "\n",
    "    col_titles = [\"Reference\", \"Prediction\", \"Absolute Error\"]\n",
    "    cbar_labels = [r\"$u_{\\mathrm{ref}}$\", r\"$u_{\\mathrm{pred}}$\", r\"$|u_{\\mathrm{pred}}-u_{\\mathrm{ref}}|$\"]\n",
    "\n",
    "    for i in range(nrows):\n",
    "        ref = refsols[i]\n",
    "        pred = u_preds[i]\n",
    "        diff = np.abs(pred - ref)\n",
    "\n",
    "        panels = [ref.T, pred.T, diff.T]\n",
    "        for j in range(3):\n",
    "            ax = axs[i, j]\n",
    "            img = ax.imshow(panels[j], origin='lower', aspect='auto', extent=extent, cmap=cmap)\n",
    "\n",
    "            # column titles only on top row\n",
    "            if i == 0:\n",
    "                ax.set_title(col_titles[j], fontsize=TITLE_FS)\n",
    "\n",
    "            if j == 2 and row_titles is not None:\n",
    "                ax.annotate(\n",
    "                    row_titles[i],\n",
    "                    xy=(1.70, 0.5), xycoords='axes fraction',   # just to the right of the panel\n",
    "                    ha='left', va='center',\n",
    "                    rotation=90,\n",
    "                    fontsize=TITLE_FS\n",
    "                )\n",
    "\n",
    "            if i == nrows - 1:\n",
    "                ax.set_xlabel(r\"$x$\", fontsize=LABEL_FS)\n",
    "            else:\n",
    "                ax.set_xlabel(\"\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(r\"$y$\", fontsize=LABEL_FS)\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "    \n",
    "            ax.tick_params(axis='both', which='major', labelsize=TICK_FS)\n",
    "\n",
    "            # apply clims\n",
    "            if j == 0:\n",
    "                clim = _clim_for(clim_ref, i)\n",
    "            elif j == 1:\n",
    "                clim = _clim_for(clim_pred, i)\n",
    "            else:\n",
    "                clim = _clim_for(clim_diff, i)\n",
    "            if clim is not None:\n",
    "                img.set_clim(*clim)\n",
    "\n",
    "            # colorbar below each subplot\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.15)  # wider cbar\n",
    "            cbar = fig.colorbar(img, cax=cax, orientation='vertical')\n",
    "            \n",
    "            # formatter only for 3rd column; fixed ticks for others\n",
    "            if j == 2:\n",
    "                cbar.formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "                cbar.formatter.set_scientific(True)\n",
    "                cbar.formatter.set_powerlimits((0, 0))\n",
    "                cbar.formatter.set_useOffset(False)\n",
    "                cbar.update_ticks()\n",
    "                offset_text = cbar.ax.yaxis.get_offset_text()\n",
    "                offset_text.set_fontsize(TICK_FS)\n",
    "                offset_text.set_x(7.5)\n",
    "\n",
    "                cbar.ax.tick_params(labelsize=TICK_FS)\n",
    "                cbar.set_label(cbar_labels[j], fontsize=LABEL_FS, labelpad=10)\n",
    "            else:\n",
    "                cbar.set_ticks([-1, 0, 1])\n",
    "                #cbar.set_ticks([-1, -0.5, 0, 0.5, 1])\n",
    "            \n",
    "                cbar.ax.tick_params(labelsize=TICK_FS)\n",
    "                cbar.set_label(cbar_labels[j], fontsize=LABEL_FS, labelpad=6)\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(left=0.12, wspace=0.65, hspace=0.3, bottom=0.0)\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(f\"{plots_dir}/final_poisson.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8722c38-dfbf-4d10-9cb8-f7aab118bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_ref_diff_grid(\n",
    "    u_preds=[pred1, pred2, pred4],\n",
    "    refsols=[refsol1, refsol2, refsol4],\n",
    "    x=x, t=y,\n",
    "    row_titles=[r\"$\\omega=1$\", r\"$\\omega=2$\", r\"$\\omega=4$\"],\n",
    "    clim_ref=None, clim_pred=None, clim_diff=None,\n",
    "    save_fig=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339947a-2a58-4bbc-a445-ea99a35b4dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
