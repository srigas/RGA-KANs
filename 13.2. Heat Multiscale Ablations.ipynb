{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec527c6a",
   "metadata": {},
   "source": [
    "# Experiment 13.2: Heat Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278a3f4-5bd3-4066-85f0-66dd913e10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "\n",
    "from src.equations import heat_multiscale_res as pde_res\n",
    "\n",
    "from src.utils import _get_adam, _get_pde_collocs, _get_ic_collocs, model_eval, count_params, _get_colloc_indices, grad_norm\n",
    "from src.wrappers import HeatMultiscaleModel\n",
    "\n",
    "import numpy as np\n",
    "from jax import device_get\n",
    "\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "result_file = os.path.join(results_dir, \"ablations_heat.pkl\")\n",
    "\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "RESULTS = dict()\n",
    "        \n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4982605-aa0e-45c7-ae10-e1122f14a6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d07314da-e027-4e2a-adcc-b7435de2569e",
   "metadata": {},
   "source": [
    "## Data & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8a8e1-9d4a-460c-b8c0-e124b1d80fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for 3D collocation points (t, x, y)\n",
    "def _get_pde_collocs_3d(t_range, x_range, y_range, sample_size_t, sample_size_xy):\n",
    "    \"\"\"Generate collocation points for 3D (t, x, y) domain.\"\"\"\n",
    "    t = jnp.linspace(t_range[0], t_range[1], sample_size_t)\n",
    "    x = jnp.linspace(x_range[0], x_range[1], sample_size_xy)\n",
    "    y = jnp.linspace(y_range[0], y_range[1], sample_size_xy)\n",
    "    T, X, Y = jnp.meshgrid(t, x, y, indexing='ij')\n",
    "    collocs_pool = jnp.stack([T.flatten(), X.flatten(), Y.flatten()], axis=1)\n",
    "    return collocs_pool\n",
    "\n",
    "\n",
    "def _get_ic_collocs_2d(x_range, y_range, sample_size):\n",
    "    \"\"\"Generate IC collocation points for 2D spatial domain at t=0.\"\"\"\n",
    "    t = jnp.array([0.0], dtype=float)\n",
    "    x = jnp.linspace(x_range[0], x_range[1], sample_size)\n",
    "    y = jnp.linspace(y_range[0], y_range[1], sample_size)\n",
    "    T, X, Y = jnp.meshgrid(t, x, y, indexing='ij')\n",
    "    ic_collocs = jnp.stack([T.flatten(), X.flatten(), Y.flatten()], axis=1)\n",
    "    return ic_collocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b721967-d447-40d6-88af-4281d5e7f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocation points for PDE residual (t, x, y)\n",
    "# Using smaller grid for collocation pool due to 3D nature\n",
    "collocs_pool = _get_pde_collocs_3d(t_range=(0, 1), x_range=(0, 1), y_range=(0, 1), \n",
    "                                   sample_size_t=50, sample_size_xy=50)\n",
    "\n",
    "# IC collocation points at t=0\n",
    "ic_collocs = _get_ic_collocs_2d(x_range=(0, 1), y_range=(0, 1), sample_size=64)\n",
    "\n",
    "# IC data: u(x, y, 0) = sin(20πx)sin(πy)\n",
    "ic_data = (jnp.sin(20 * jnp.pi * ic_collocs[:, 1]) * jnp.sin(jnp.pi * ic_collocs[:, 2])).reshape(-1, 1)\n",
    "\n",
    "# Reference solution\n",
    "ref = np.load('data/heat.npz')\n",
    "refsol = jnp.array(ref['usol'])\n",
    "\n",
    "N_t, N_x, N_y = ref['usol'].shape\n",
    "t, x, y = ref['t'].flatten(), ref['x'].flatten(), ref['y'].flatten()\n",
    "T, X, Y = jnp.meshgrid(t, x, y, indexing='ij')\n",
    "coords = jnp.hstack([T.flatten()[:, None], X.flatten()[:, None], Y.flatten()[:, None]])\n",
    "\n",
    "print(f\"Collocs pool shape: {collocs_pool.shape}\")\n",
    "print(f\"IC collocs shape: {ic_collocs.shape}\")\n",
    "print(f\"Reference solution shape: {refsol.shape}\")\n",
    "print(f\"Coords shape: {coords.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46423f-123e-48e6-b026-64f8dbdcb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training epochs\n",
    "num_epochs = 100_000\n",
    "\n",
    "# Scheduler configurations\n",
    "learning_rate = 1e-3\n",
    "decay_steps = 2000\n",
    "decay_rate = 0.9\n",
    "warmup_steps = 1000\n",
    "\n",
    "# Define causal training parameters\n",
    "causal_tol = 1.0\n",
    "num_chunks = 32\n",
    "M = jnp.triu(jnp.ones((num_chunks, num_chunks)), k=1).T\n",
    "\n",
    "# Define Grad Norm parameters\n",
    "grad_mixing = 0.9\n",
    "f_grad_norm = 1000\n",
    "\n",
    "# Define resampling parameters\n",
    "batch_size = 2**12\n",
    "f_resample = 2000\n",
    "rad_a = 1.0\n",
    "rad_c = 1.0\n",
    "\n",
    "# Define RBA parameters\n",
    "RBA_gamma = 0.999\n",
    "RBA_eta = 0.01\n",
    "\n",
    "# Define model parameters\n",
    "n_in = 3  # (t, x, y)\n",
    "n_out = 1\n",
    "D = 5\n",
    "period_axes = None  # No periodic BCs\n",
    "alpha = 0.0\n",
    "beta = 1.0\n",
    "sine_D = 5\n",
    "init_scheme = {'type': 'glorot', 'gain': None, 'norm_pow': 0, 'distribution': 'uniform', 'sample_size': 10000}\n",
    "n_hidden = 16\n",
    "num_blocks = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0513d6-369d-47a2-9bb8-db938883fad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dabda9d5-bf5e-44b6-a3bc-c6d234ce7710",
   "metadata": {},
   "source": [
    "## Ablation 1: Only RBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f136c-bae3-4629-a336-978c369a256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, l_E, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Get new RBA weights\n",
    "    abs_res = jnp.abs(residuals)\n",
    "    l_E_new = (RBA_gamma*l_E) + (RBA_eta*abs_res/jnp.max(abs_res)) # shape (batch_size, 1)\n",
    "\n",
    "    # Multiply by RBA weights\n",
    "    w_resids = l_E_new * residuals # shape (batch_size, 1)\n",
    "\n",
    "    loss = jnp.mean(w_resids**2)\n",
    "    \n",
    "    return loss, l_E_new\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, l_I, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Get new RBA weights\n",
    "    abs_res = jnp.abs(ic_res)\n",
    "    l_I_new = (RBA_gamma*l_I) + (RBA_eta*abs_res/jnp.max(abs_res))\n",
    "\n",
    "    # Multiply by RBA weights\n",
    "    w_resids = l_I_new * ic_res\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(w_resids**2)\n",
    "\n",
    "    return loss, l_I_new\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I, l_E, l_I):\n",
    "\n",
    "    # PDE loss\n",
    "    (loss_E, l_E_new), grads_E = nnx.value_and_grad(pde_loss, has_aux=True)(model, l_E, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    (loss_I, l_I_new), grads_I = nnx.value_and_grad(ic_loss, has_aux=True)(model, l_I, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I, l_E_new, l_I_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e753801-6951-4332-bb51-7af57b98704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 1\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 1\"][idx] = dict()\n",
    "    \n",
    "    # Initialize RBA weights - full pool\n",
    "    l_E_pool = jnp.ones((collocs_pool.shape[0], 1))\n",
    "    # Also get RBAs for ICs\n",
    "    l_I = jnp.ones((ic_collocs.shape[0], 1))\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    l_E = l_E_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = HeatMultiscaleModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                                period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I, l_E, l_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I, l_E, l_I)\n",
    "\n",
    "    tack = time.time()\n",
    "        \n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 1\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 1\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fa8c1-aadc-4b88-8121-83796f2cc21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e3bfc-843f-4a87-9721-dfbf7f345969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "677b6be3-da8b-4a45-9ed4-75d87d07378b",
   "metadata": {},
   "source": [
    "## Ablation 2: No RBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ce7c9-7245-44ea-aa15-99253ccc00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Reshape residuals for causal training\n",
    "    residuals = residuals.reshape(num_chunks, -1) # shape (num_chunks, points)\n",
    "\n",
    "    # Get average loss per chunk\n",
    "    loss = jnp.mean(residuals**2, axis=1)\n",
    "\n",
    "    # Get causal weights\n",
    "    weights = jax.lax.stop_gradient(jnp.exp(-causal_tol * (M @ loss)))\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(weights * loss)\n",
    "\n",
    "    return weighted_loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def get_RAD_indices(model, collocs_pool, old_indices):\n",
    "\n",
    "    # Get full residuals\n",
    "    resids = pde_res(model, collocs_pool)\n",
    "    \n",
    "    # Get absolute\n",
    "    wa_resids = jnp.abs(resids)\n",
    "\n",
    "    # Raise to power rad_a\n",
    "    ea = jnp.power(wa_resids, rad_a)\n",
    "    \n",
    "    # Divide by mean and add rad_c\n",
    "    px = (ea/jnp.mean(ea)) + rad_c\n",
    "    \n",
    "    # Normalize\n",
    "    px_norm = (px / jnp.sum(px))[:,0]\n",
    "\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=px_norm, seed=seed)\n",
    "\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acec77-b800-4823-8454-88ca953af624",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 2\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 2\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = HeatMultiscaleModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                                period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "        \n",
    "        # Perform grad norm\n",
    "        if (epoch != 0) and (epoch % f_grad_norm == 0):\n",
    "    \n",
    "            λ_Ε, λ_I = grad_norm(grads_E, grads_I, λ_E, λ_I, grad_mixing)\n",
    "    \n",
    "        # Perform RAD\n",
    "        if (epoch != 0) and (epoch % f_resample == 0):\n",
    "\n",
    "            # Get new indices after resampling\n",
    "            sorted_indices = get_RAD_indices(model, collocs_pool, sorted_indices)\n",
    "            # Set new batch of collocs\n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 2\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 2\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebd56c-cdeb-49a3-b347-6f32f62e9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 2\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18f45c-7de2-4710-8809-38fd98141407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd5054ca-9c03-4ad7-ab91-d2dc10daa62e",
   "metadata": {},
   "source": [
    "## Ablation 3: No RBA & No RAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d75b8-e041-4ccf-aaf3-0b35d7b1f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Reshape residuals for causal training\n",
    "    residuals = residuals.reshape(num_chunks, -1) # shape (num_chunks, points)\n",
    "\n",
    "    # Get average loss per chunk\n",
    "    loss = jnp.mean(residuals**2, axis=1)\n",
    "\n",
    "    # Get causal weights\n",
    "    weights = jax.lax.stop_gradient(jnp.exp(-causal_tol * (M @ loss)))\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(weights * loss)\n",
    "\n",
    "    return weighted_loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3019b-a43a-49e4-a856-57c09ff53fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 3\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 3\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = HeatMultiscaleModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                                period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "        \n",
    "        # Perform grad norm\n",
    "        if (epoch != 0) and (epoch % f_grad_norm == 0):\n",
    "    \n",
    "            λ_Ε, λ_I = grad_norm(grads_E, grads_I, λ_E, λ_I, grad_mixing)\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 3\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 3\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca65d97-f39a-419d-95ad-40731e2a9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 3\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2bfa2-171c-4752-b111-5d11fa60a5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a72e3c1-ad9f-451b-91d9-7119db3414bd",
   "metadata": {},
   "source": [
    "## Ablation 4: No RBA & No Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736eb49-7484-4209-af84-cc8f3be0ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # loss\n",
    "    loss = jnp.mean(residuals**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def get_RAD_indices(model, collocs_pool, old_indices):\n",
    "\n",
    "    # Get full residuals\n",
    "    resids = pde_res(model, collocs_pool)\n",
    "    \n",
    "    # Get absolute\n",
    "    wa_resids = jnp.abs(resids)\n",
    "\n",
    "    # Raise to power rad_a\n",
    "    ea = jnp.power(wa_resids, rad_a)\n",
    "    \n",
    "    # Divide by mean and add rad_c\n",
    "    px = (ea/jnp.mean(ea)) + rad_c\n",
    "    \n",
    "    # Normalize\n",
    "    px_norm = (px / jnp.sum(px))[:,0]\n",
    "\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=px_norm, seed=seed)\n",
    "\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fd9bd-6dd3-4f7f-a075-15d03f63b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 4\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 4\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = HeatMultiscaleModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                                period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "        \n",
    "        # Perform grad norm\n",
    "        if (epoch != 0) and (epoch % f_grad_norm == 0):\n",
    "    \n",
    "            λ_Ε, λ_I = grad_norm(grads_E, grads_I, λ_E, λ_I, grad_mixing)\n",
    "    \n",
    "        # Perform RAD\n",
    "        if (epoch != 0) and (epoch % f_resample == 0):\n",
    "\n",
    "            # Get new indices after resampling\n",
    "            sorted_indices = get_RAD_indices(model, collocs_pool, sorted_indices)\n",
    "            # Set new batch of collocs\n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 4\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 4\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7472e-5f27-45cc-b9eb-0a7a08de6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 4\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd15f2-a602-4003-8980-60f38b5f7f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08bf9b7f-7a27-430f-9a05-cffa144516fd",
   "metadata": {},
   "source": [
    "## Ablation 5: No RBA & No Grad Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff87ec4-2650-417c-ad62-c568f17d14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE Loss\n",
    "def pde_loss(model, collocs):\n",
    "\n",
    "    residuals = pde_res(model, collocs) # shape (batch_size, 1)\n",
    "\n",
    "    # Reshape residuals for causal training\n",
    "    residuals = residuals.reshape(num_chunks, -1) # shape (num_chunks, points)\n",
    "\n",
    "    # Get average loss per chunk\n",
    "    loss = jnp.mean(residuals**2, axis=1)\n",
    "\n",
    "    # Get causal weights\n",
    "    weights = jax.lax.stop_gradient(jnp.exp(-causal_tol * (M @ loss)))\n",
    "\n",
    "    # Weighted loss\n",
    "    weighted_loss = jnp.mean(weights * loss)\n",
    "\n",
    "    return weighted_loss\n",
    "\n",
    "\n",
    "# IC Loss\n",
    "def ic_loss(model, ic_collocs, ic_data):\n",
    "\n",
    "    # Residual\n",
    "    ic_res = model(ic_collocs) - ic_data\n",
    "\n",
    "    # Loss\n",
    "    loss = jnp.mean(ic_res**2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I):\n",
    "\n",
    "    # PDE loss\n",
    "    loss_E, grads_E = nnx.value_and_grad(pde_loss, has_aux=False)(model, collocs)\n",
    "\n",
    "    # IC loss\n",
    "    loss_I, grads_I = nnx.value_and_grad(ic_loss, has_aux=False)(model, ic_collocs, ic_data)\n",
    "    \n",
    "    # Compute total loss\n",
    "    loss = λ_E*loss_E + λ_I*loss_I\n",
    "\n",
    "    # Compute total gradients\n",
    "    grads = jax.tree_util.tree_map(lambda g1, g2: λ_E * g1 + λ_I * g2, grads_E, grads_I)\n",
    "\n",
    "    # Optimizer step\n",
    "    optimizer.update(grads)\n",
    "\n",
    "    return loss, grads_E, grads_I\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def get_RAD_indices(model, collocs_pool, old_indices):\n",
    "\n",
    "    # Get full residuals\n",
    "    resids = pde_res(model, collocs_pool)\n",
    "    \n",
    "    # Get absolute\n",
    "    wa_resids = jnp.abs(resids)\n",
    "\n",
    "    # Raise to power rad_a\n",
    "    ea = jnp.power(wa_resids, rad_a)\n",
    "    \n",
    "    # Divide by mean and add rad_c\n",
    "    px = (ea/jnp.mean(ea)) + rad_c\n",
    "    \n",
    "    # Normalize\n",
    "    px_norm = (px / jnp.sum(px))[:,0]\n",
    "\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=px_norm, seed=seed)\n",
    "\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf6055-9228-4e26-913b-3d2582dbf475",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"Ablation 5\"] = dict()\n",
    "\n",
    "for idx, run in enumerate([0, 7, 42]):\n",
    "\n",
    "    RESULTS[\"Ablation 5\"][idx] = dict()\n",
    "\n",
    "    # Get starting collocation points & RBA weights\n",
    "    sorted_indices = _get_colloc_indices(collocs_pool=collocs_pool, batch_size=batch_size, px=None, seed=seed)\n",
    "    \n",
    "    collocs = collocs_pool[sorted_indices]\n",
    "    \n",
    "    # Get opt_type\n",
    "    opt_type = _get_adam(learning_rate=learning_rate, decay_steps=decay_steps, decay_rate=decay_rate, warmup_steps=warmup_steps)\n",
    "\n",
    "    # Define model\n",
    "    model = HeatMultiscaleModel(n_in = n_in, n_out = n_out, n_hidden = n_hidden, num_blocks = num_blocks, D = D,\n",
    "                                init_scheme = init_scheme, alpha = alpha, beta = beta, ref = ref,\n",
    "                                period_axes = period_axes, rff_std = None, sine_D = sine_D, seed = seed+run)\n",
    "\n",
    "    if idx == 0:\n",
    "        print(f\"Initialized model with {count_params(model)} parameters.\")\n",
    "    \n",
    "    # Define global loss weights\n",
    "    λ_E = jnp.array(1.0, dtype=float)\n",
    "    λ_I = jnp.array(1.0, dtype=float)\n",
    "\n",
    "    # Set optimizer\n",
    "    optimizer = nnx.Optimizer(model, opt_type)\n",
    "    \n",
    "    tick = time.time()\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        loss, grads_E, grads_I = train_step(model, optimizer, collocs, ic_collocs, ic_data, λ_E, λ_I)\n",
    "    \n",
    "        # Perform RAD\n",
    "        if (epoch != 0) and (epoch % f_resample == 0):\n",
    "\n",
    "            # Get new indices after resampling\n",
    "            sorted_indices = get_RAD_indices(model, collocs_pool, sorted_indices)\n",
    "            # Set new batch of collocs\n",
    "            collocs = collocs_pool[sorted_indices]\n",
    "\n",
    "    tack = time.time()\n",
    "\n",
    "    l2error = model_eval(model, coords, refsol)\n",
    "\n",
    "    print(f\"\\tRun = {idx}\\t L^2 = {l2error:.2e}\\t Loss = {loss:.2e}\\t Time = {(tack-tick)/60:.2f} mins\")\n",
    "\n",
    "    RESULTS[\"Ablation 5\"][idx]['time'] = tack-tick\n",
    "    RESULTS[\"Ablation 5\"][idx]['l2'] = l2error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4d3ad-5c66-4433-8ea3-8f803c1e9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 5\n",
    "with open(result_file, \"wb\") as f:\n",
    "    pickle.dump(RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b1c08-7431-48d5-a2a6-646b8fb8245e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e51390cf-cc31-4def-9053-05ccc98fda77",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(result_file, \"rb\") as f:\n",
    "    RESULTS = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(results_dir, \"benchmarks_heat.pkl\"), \"rb\") as f:\n",
    "    rbn = pickle.load(f)\n",
    "\n",
    "rbn = rbn[(alpha,beta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42091f0-9727-4bbd-bf43-841643df3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(results, rbn):\n",
    "\n",
    "    l2_values = []\n",
    "    times = []\n",
    "    for run in rbn.keys():\n",
    "        l2_values.append(rbn[run]['l2'])\n",
    "        times.append(rbn[run]['time'])\n",
    "\n",
    "    mean = np.mean(l2_values)\n",
    "    sem = np.std(l2_values, ddof=1) / np.sqrt(len(l2_values))\n",
    "\n",
    "    mean_t = np.mean(times)\n",
    "\n",
    "    print(f\"Original:\\t L^2 = {mean:.3e} ± {sem:.3e}\\t | \\tTime = {1000*mean_t:.2f} ms/it\")\n",
    "    \n",
    "    for ablation, runs in results.items():\n",
    "        l2_values = [v['l2'] for v in runs.values()]\n",
    "        times = [v['time'] for v in runs.values()]\n",
    "        \n",
    "        mean = np.mean(l2_values)\n",
    "        sem = np.std(l2_values, ddof=1) / np.sqrt(len(l2_values))\n",
    "\n",
    "        mean_t = np.mean(times)/num_epochs\n",
    "        print(f\"{ablation}:\\t L^2 = {mean:.3e} ± {sem:.3e}\\t | \\tTime = {1000*mean_t:.2f} ms/it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc71ff-7881-4d46-b6e7-f6c4a9a60f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(RESULTS, rbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45611735-7c69-4239-869d-7f23aa13e807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
